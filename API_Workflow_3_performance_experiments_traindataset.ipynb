{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886ecf79",
   "metadata": {
    "id": "886ecf79"
   },
   "source": [
    "# **Notebook 3: Fusion Experiments**\n",
    "In this notebook, we conduct experiments to answer two questions:\n",
    "1. How should we combine the outputs of each input modality?\n",
    "2. How should we predict basic emotions and binary sentiment from complex emotion?\n",
    "\n",
    "Read on for a more detailed explanation of both questions :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsRSpa3IbBfV",
   "metadata": {
    "id": "VsRSpa3IbBfV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Initialization and Data Processing**\n",
    "We load a JSON of the sentence-by-sentence Hume predictions on the full MELD dataset. See the previous workbooks for how that JSON is generated and cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e95c11",
   "metadata": {
    "id": "99e95c11"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f516e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_to_df(directory):\n",
    "    '''\n",
    "    converts JSON output to a PD dataframe\n",
    "    each JSON contains the predicted emotions for one sentence\n",
    "    '''\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = json.load(file)\n",
    "                metadata = content['metadata']\n",
    "\n",
    "                # sentiment data\n",
    "                face_emotions = lowercase_keys(content['predicted']['face'])\n",
    "                prosody_emotions = lowercase_keys(content['predicted']['prosody'])\n",
    "                lang_emotions = lowercase_keys(content['predicted']['lang'])\n",
    "\n",
    "                data.append({\n",
    "                    'dialogue_id': metadata['dialogue_id'],\n",
    "                    'time_start': metadata['time_start'],\n",
    "                    'time_end': metadata['time_end'],\n",
    "                    'speaker': metadata['speaker'],\n",
    "                    'emotion': metadata['emotion'],\n",
    "                    'sentiment': metadata['sentiment'],\n",
    "                    'text_content': metadata['text_content'],\n",
    "                    'file_name': metadata['file_name'],\n",
    "                    'face': face_emotions,\n",
    "                    'prosody': prosody_emotions,\n",
    "                    'lang': lang_emotions\n",
    "                })\n",
    "                \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df6b370-4e71-4d2e-9b4a-9b97cc2fc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_keys(dictionary):\n",
    "    '''\n",
    "    changes all (String) keys in a dictionary to be fully lower case\n",
    "    '''\n",
    "    return {key.lower(): value for key, value in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020de35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = './dataset/outputs/merged_all'\n",
    "df = load_json_to_df(dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec4a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_scores(df):\n",
    "    '''\n",
    "    adds a column for each Hume/complex emotion, which contains a list of form [face_intensity, prosody_intensity, language_intensity]\n",
    "    '''\n",
    "    df_with_emotions = df.copy()\n",
    "    for emotion in all_emotions:\n",
    "        df_with_emotions[emotion] = df.apply(lambda row: [\n",
    "            row['face'].get(emotion, None),\n",
    "            row['prosody'].get(emotion, None),\n",
    "            row['lang'].get(emotion, None)\n",
    "        ], axis=1)\n",
    "            \n",
    "    return df_with_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260b52e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Exploring Our Emotion Data**\n",
    "Hume has three models that predict emotion based on different modality. One model predicts based on language (the words spoken), another based on prosody (tone of voice, pauses, and vocables), and the last on facial expression. The prosody and face models output 48 emotions. The language model outputs 53 emotions. The five additional emotions output by the language model are {'Annoyance', 'Disapproval', 'Enthusiasm', 'Gratitude', 'Sarcasm'}.\n",
    "\n",
    "Critically, the MELD dataset contains many sentences labeled with the 7 basic emotions (anger, sadness, fear, joy, surprise, disgust, and neutral). The Hume outputs are _not_ the same as the MELD dataset labels. Going forward, we will refer to the Hume outputs as \"complex emotions\" and the MELD dataset labels as \"basic emotions.\" As you'll see below, a key part of our work is reducing predictions about \"complex emotions\" to predictions about \"basic emotions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7355fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputted emotions in lang, prosody, and face models: 53 48 0\n",
      "Emotions outputted by language model but not prosody model: {'disapproval', 'gratitude', 'annoyance', 'sarcasm', 'enthusiasm'}\n",
      "Emotions outputted by prosody model but not face model: {'pride', 'boredom', 'sympathy', 'amusement', 'entrancement', 'distress', 'contempt', 'aesthetic appreciation', 'horror', 'relief', 'embarrassment', 'anger', 'desire', 'romance', 'tiredness', 'disappointment', 'excitement', 'surprise (positive)', 'envy', 'awkwardness', 'craving', 'anxiety', 'joy', 'admiration', 'calmness', 'empathic pain', 'interest', 'shame', 'surprise (negative)', 'awe', 'concentration', 'sadness', 'disgust', 'contentment', 'doubt', 'triumph', 'ecstasy', 'nostalgia', 'determination', 'adoration', 'guilt', 'fear', 'satisfaction', 'love', 'pain', 'realization', 'confusion', 'contemplation'}\n",
      "All emotions: ['admiration', 'adoration', 'aesthetic appreciation', 'amusement', 'anger', 'annoyance', 'anxiety', 'awe', 'awkwardness', 'boredom', 'calmness', 'concentration', 'confusion', 'contemplation', 'contempt', 'contentment', 'craving', 'desire', 'determination', 'disappointment', 'disapproval', 'disgust', 'distress', 'doubt', 'ecstasy', 'embarrassment', 'empathic pain', 'enthusiasm', 'entrancement', 'envy', 'excitement', 'fear', 'gratitude', 'guilt', 'horror', 'interest', 'joy', 'love', 'nostalgia', 'pain', 'pride', 'realization', 'relief', 'romance', 'sadness', 'sarcasm', 'satisfaction', 'shame', 'surprise (negative)', 'surprise (positive)', 'sympathy', 'tiredness', 'triumph']\n"
     ]
    }
   ],
   "source": [
    "lang_emotions = set(df['lang'][0].keys())\n",
    "prosody_emotions = set(df['prosody'][0].keys())\n",
    "face_emotions = set(df['face'][0].keys())\n",
    "\n",
    "print(\"Number of outputted emotions in lang, prosody, and face models:\", len(lang_emotions), len(prosody_emotions), len(face_emotions))\n",
    "print(\"Emotions outputted by language model but not prosody model:\", lang_emotions-prosody_emotions)\n",
    "print(\"Emotions outputted by prosody model but not face model:\", prosody_emotions-face_emotions)\n",
    "\n",
    "all_emotions = sorted(list(lang_emotions))\n",
    "print('All emotions:', all_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ef820-b517-478d-8d8b-1bcfb198db18",
   "metadata": {},
   "source": [
    "### **Emotion Maps**\n",
    "\n",
    "Below, we create maps from the output of Hume AI (up to 53 emotions) to the seven basic emotions in our dataset. We also map the Hume AI emotions to positive/negative sentiment. Annotations below are manually created. Interesting future exploration could involve mapping each Hume/complex emotion to a weighted sum of the 7 basic emotions, potentially through training an ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4123edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASIC_TO_COMPLEX = {\n",
    "  'anger': ['anger', 'annoyance', 'disapproval'],\n",
    "  'fear': ['anxiety', 'doubt', 'fear', 'horror'],\n",
    "  'joy': ['admiration', 'adoration', 'amusement', 'contentment', 'desire', 'ecstasy', 'enthusiasm', 'entrancement', 'excitement', 'gratitude', 'joy', 'love', 'pride', 'relief', 'romance', 'triumph'],\n",
    "  'sadness': ['disappointment', 'distress', 'empathic pain', 'guilt', 'nostalgia', 'pain', 'sadness'],\n",
    "  'surprise': ['awe', 'confusion', 'realization', 'surprise (negative)', 'surprise (positive)'],\n",
    "  'disgust': ['contempt', 'disgust', 'envy', 'sarcasm'],\n",
    "  'neutral': ['aesthetic appreciation', 'awkwardness', 'boredom', 'calmness', 'concentration', 'contemplation', 'craving', 'determination', 'embarrassment', 'interest', 'satisfaction', 'shame', 'sympathy', 'tiredness']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99fad0fe-1e8f-4cc6-9f1f-f320a0e10730",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_TO_EMOTION = {\n",
    "  'positive': [\n",
    "    'admiration', 'adoration', 'aesthetic appreciation', 'amusement', 'awe', 'contentment', 'desire', 'ecstasy', 'enthusiasm', 'entrancement', 'excitement', 'gratitude', 'joy', 'love', 'pride', 'relief', 'romance', 'triumph'\n",
    "  ],\n",
    "  'negative': [\n",
    "    'anger', 'annoyance', 'anxiety', 'awkwardness', 'boredom', 'contempt', 'confusion', 'craving', 'disappointment', 'disapproval', 'disgust', 'distress', 'doubt', 'empathic pain', 'embarrassment', 'envy', 'fear', 'guilt', 'horror', 'nostalgia', 'pain', 'sadness', 'sarcasm', 'shame', 'surprise (negative)', 'sympathy', 'tiredness'\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7befd-85b5-44a5-b24e-1f4883e74785",
   "metadata": {},
   "source": [
    "## **Methods To Fuse Modalities**\n",
    "Hume has a facial expression model (predicts based on frame capture of facial expressions in a video), a prosody model (predicts based on signal waveform), and language model (predicts based off words spoken). Each model outputs predictions for up to 53 emotions based on the given input modality. We experiment with two methods to combine the outputs from different modalities to obtain a single number representing the intensity of each emotion.\n",
    "1. The first method is a simple sum. To get the intensity of an emotion, this function sums the intensity predicated for each modality. In other words: `awe_intensity = face_awe_intensity + prosody_awe_intensity + lang_awe_intensity`\n",
    "2. The second method is a relative sum. To get the intensity of an emotion, this function takes sums the intensity predicated for each modality, weighted by the predictive accuracy of that modality alone. In other words: `awe_intensity = face_awe_intensity * relative accuracy of face-only prediction + ... (the same for prosody and language)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42216b4e-170b-40b8-bb38-dafbbface205",
   "metadata": {},
   "source": [
    "### **Method 1: Simple Sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e262ed7a-5680-421d-bc2f-df7d964b2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_sum(df):\n",
    "    '''\n",
    "    to get the intensity of an emotion, this function sums the intensity predicated for each modality. In other words:\n",
    "    awe_intensity = face_awe_intensity + prosody_awe_intensity + lang_awe_intensity\n",
    "    '''\n",
    "    simple_sum_df = df.copy()\n",
    "    for emotion in all_emotions:\n",
    "        simple_sum_df[emotion] = df[emotion].apply(lambda x: sum([i for i in x if i is not None]))\n",
    "    return simple_sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018bf0c-6432-4b3d-9443-d19a20121bdb",
   "metadata": {},
   "source": [
    "### **Method 2: Relative Sum**\n",
    "We calculate the extent to which each individual modality predicts the final emotion, and use the relative accuracy of each modality to weight the final sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f630fc-1ed3-4207-a16e-7c123b58d0d0",
   "metadata": {},
   "source": [
    "#### **2a: Accuracy of Individual Modalities**\n",
    "First, we test each individual modality to see how predictive it is of the final emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b17183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df, mapping, modality):\n",
    "    '''\n",
    "    predicts which basic emotion dominates by taking the mean of all complex emotions corresponding to that basic emotion, and choosing the basic emotion with the highest intensity\n",
    "    '''\n",
    "    intensities = pd.DataFrame()\n",
    "    basic_emotions = sorted(list(mapping.keys()))\n",
    "    \n",
    "    for basic_emotion in basic_emotions:\n",
    "        # this is a disgusting list comprehension that came from flattening a long loop\n",
    "        complex_emotions = pd.concat([df[modality].apply(lambda row: row.get(complex_emotion, np.nan)).rename(complex_emotion) for complex_emotion in mapping[basic_emotion]], axis=1)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            intensities[basic_emotion] = np.nanmean(complex_emotions, axis=1) # column names: basic emotions; each row is a sentence; values are the intensities of the basic emotion for that sentence\n",
    "\n",
    "    # drop all rows that have all nan values\n",
    "    intensities = intensities.dropna(how='all')\n",
    "    \n",
    "    y_pred = intensities.idxmax(axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbd63eb-ea30-4cd4-bc12-5e65c8edc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, target, modality):\n",
    "    '''\n",
    "    reports the accuracy of the approach above compared to ground truth\n",
    "    @param df with a column `y_pred` and a column with the name `target`\n",
    "    @returns the percent of rows that have identical `y_pred` and `target` values\n",
    "    ''' \n",
    "    if target == 'emotion':\n",
    "        mapping = BASIC_TO_COMPLEX\n",
    "    elif target == 'sentiment':\n",
    "        mapping = SENTIMENT_TO_EMOTION\n",
    "    else:\n",
    "        raise Exception('Invalid target')\n",
    "        \n",
    "    y_pred = get_predictions(df, mapping, modality)\n",
    "    comparable_columns = df[target].loc[y_pred.index]\n",
    "    total_sentences = len(comparable_columns)\n",
    "    accuracy = np.sum(y_pred == comparable_columns) / total_sentences\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9c7c05-f597-492e-95c5-b56e305523ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relative_weights(df, show_results=False):\n",
    "    # run on all combinations of emotions and modalities\n",
    "    targets = ['emotion', 'sentiment']\n",
    "    modalities = ['face','prosody','lang']\n",
    "    \n",
    "    results = pd.DataFrame(index=targets, columns=modalities)\n",
    "    \n",
    "    for target in targets:\n",
    "        for modality in modalities:\n",
    "            accuracy = get_accuracy(df, target, modality)\n",
    "            results.at[target, modality] = accuracy\n",
    "    results = results.astype(float)\n",
    "\n",
    "    # calculate and return relative weights\n",
    "    relative_weights = results.apply(lambda row: row / np.sum(row), axis=1)\n",
    "    \n",
    "    if show_results:\n",
    "        print(\"Accuracy by Modality\")\n",
    "        display(results)\n",
    "        print(\"Relative Modality Weights\")\n",
    "        display(relative_weights)\n",
    "    \n",
    "        # plot heatmap\n",
    "        fig, ax = plt.subplots()\n",
    "        heatmap = ax.imshow(results, cmap='viridis', interpolation='nearest')\n",
    "        \n",
    "        ax.set_xticks(np.arange(len(modalities)))\n",
    "        ax.set_yticks(np.arange(len(targets)))\n",
    "        ax.set_xticklabels(modalities)\n",
    "        ax.set_yticklabels(targets)\n",
    "        plt.setp(ax.get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.colorbar(heatmap)\n",
    "        \n",
    "        ax.set_title('Accuracy Scores by Target and Modality')\n",
    "        plt.xlabel('Modalities')\n",
    "        plt.ylabel('Targets')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    return relative_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91148db9-e273-4005-8022-d3815e47ee9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m unfused_data \u001b[38;5;241m=\u001b[39m get_emotion_scores(df)\n\u001b[1;32m----> 2\u001b[0m weights \u001b[38;5;241m=\u001b[39m calc_relative_weights(unfused_data, show_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mcalc_relative_weights\u001b[1;34m(df, show_results)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m modality \u001b[38;5;129;01min\u001b[39;00m modalities:\n\u001b[1;32m---> 10\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(df, target, modality)\n\u001b[0;32m     11\u001b[0m         results\u001b[38;5;241m.\u001b[39mat[target, modality] \u001b[38;5;241m=\u001b[39m accuracy\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mget_accuracy\u001b[1;34m(df, target, modality)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid target\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_predictions(df, mapping, modality)\n\u001b[0;32m     15\u001b[0m comparable_columns \u001b[38;5;241m=\u001b[39m df[target]\u001b[38;5;241m.\u001b[39mloc[y_pred\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m     16\u001b[0m total_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(comparable_columns)\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mget_predictions\u001b[1;34m(df, mapping, modality)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# drop all rows that have all nan values\u001b[39;00m\n\u001b[0;32m     17\u001b[0m intensities \u001b[38;5;241m=\u001b[39m intensities\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m intensities\u001b[38;5;241m.\u001b[39midxmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10635\u001b[0m, in \u001b[0;36mDataFrame.idxmax\u001b[1;34m(self, axis, skipna, numeric_only)\u001b[0m\n\u001b[0;32m  10632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10633\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m> 10635\u001b[0m res \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  10636\u001b[0m     nanops\u001b[38;5;241m.\u001b[39mnanargmax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m  10637\u001b[0m )\n\u001b[0;32m  10638\u001b[0m indices \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  10640\u001b[0m \u001b[38;5;66;03m# indices will always be np.ndarray since axis is not None and\u001b[39;00m\n\u001b[0;32m  10641\u001b[0m \u001b[38;5;66;03m# values is a 2d array for DataFrame\u001b[39;00m\n\u001b[0;32m  10642\u001b[0m \u001b[38;5;66;03m# error: Item \"int\" of \"Union[int, Any]\" has no attribute \"__iter__\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10504\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10499\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m  10500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m  10501\u001b[0m         \u001b[38;5;66;03m# Taking a transpose would result in no columns, losing the dtype.\u001b[39;00m\n\u001b[0;32m  10502\u001b[0m         \u001b[38;5;66;03m# In the empty case, reducing along axis 0 or 1 gives the same\u001b[39;00m\n\u001b[0;32m  10503\u001b[0m         \u001b[38;5;66;03m# result dtype, so reduce with axis=0 and ignore values\u001b[39;00m\n\u001b[1;32m> 10504\u001b[0m         result \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  10505\u001b[0m             op,\n\u001b[0;32m  10506\u001b[0m             name,\n\u001b[0;32m  10507\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m  10508\u001b[0m             skipna\u001b[38;5;241m=\u001b[39mskipna,\n\u001b[0;32m  10509\u001b[0m             numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m  10510\u001b[0m             filter_type\u001b[38;5;241m=\u001b[39mfilter_type,\n\u001b[0;32m  10511\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m  10512\u001b[0m         )\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10513\u001b[0m         result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m  10514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10482\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1147\u001b[0m, in \u001b[0;36mnanargmax\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1145\u001b[0m values, mask, _, _, _ \u001b[38;5;241m=\u001b[39m _get_values(values, \u001b[38;5;28;01mTrue\u001b[39;00m, fill_value_typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;66;03m# error: Need type annotation for 'result'\u001b[39;00m\n\u001b[1;32m-> 1147\u001b[0m result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39margmax(axis)  \u001b[38;5;66;03m# type: ignore[var-annotated]\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_arg_null_out(result, axis, mask, skipna)\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "unfused_data = get_emotion_scores(df)\n",
    "weights = calc_relative_weights(unfused_data, show_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc58fa1-903a-4873-a8e5-b9b2cf75e789",
   "metadata": {},
   "source": [
    "#### **2b: Fusion**\n",
    "And now let's put those relative weights to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d02dae-2f97-4fcd-92f0-6ef10a17f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_weights(df, target):\n",
    "    '''\n",
    "    to get the intensity of an emotion, this function takes sums the intensity predicated for each modality, weighted by the predictive accuracy of that modality alone. In other words:\n",
    "    awe_intensity = face_awe_intensity * relative accuracy of face-only prediction + ... (the same for prosody and language)\n",
    "    '''\n",
    "    weights_df = df.copy()\n",
    "    # df with rows of form [face_weight, prosody_weight, lang_weight]\n",
    "    weights = calc_relative_weights(df)\n",
    "    target_weights = list(weights.loc[target])\n",
    "    for emotion in all_emotions:\n",
    "        weights_df[emotion] = df[emotion].apply(lambda row: sum([modality * weight for modality, weight in zip(row, target_weights) if modality is not None]))\n",
    "    return weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ddfd17-e955-410f-a7d8-8ad568bf68f0",
   "metadata": {},
   "source": [
    "#### **Fused Data**\n",
    "You can see the results below for unfused data, the simple sum, and the relative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3805800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>adoration</th>\n",
       "      <th>aesthetic appreciation</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awe</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>romance</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise (negative)</th>\n",
       "      <th>surprise (positive)</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.051815811544656754, 0.015896273776888847, 0...</td>\n",
       "      <td>[0.046310193836688995, 0.005779789295047522, 0...</td>\n",
       "      <td>[0.04528449475765228, 0.008344665169715881, 0....</td>\n",
       "      <td>[0.05977936461567879, 0.06531573086977005, 0.0...</td>\n",
       "      <td>[0.08618035167455673, 0.014928092248737812, 0....</td>\n",
       "      <td>[None, None, 0.0787773035466671]</td>\n",
       "      <td>[0.2048976570367813, 0.22192993760108948, 0.01...</td>\n",
       "      <td>[0.05436728522181511, 0.02884811908006668, 0.0...</td>\n",
       "      <td>[0.15164369344711304, 0.03940080106258392, 0.0...</td>\n",
       "      <td>[0.3025617003440857, 0.0033794636838138103, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.03606966510415077, 0.003395841922610998, 0....</td>\n",
       "      <td>[0.5214796662330627, 0.023176860064268112, 0.0...</td>\n",
       "      <td>[None, None, 0.045924624986946584]</td>\n",
       "      <td>[0.08109661191701889, 0.00422081770375371, 0.0...</td>\n",
       "      <td>[0.13604705035686493, 0.03896016255021095, 0.0...</td>\n",
       "      <td>[0.0438678115606308, 0.12426678091287613, 0.65...</td>\n",
       "      <td>[0.021023310720920563, 0.05467357486486435, 0....</td>\n",
       "      <td>[0.07115799933671951, 0.014430238865315914, 0....</td>\n",
       "      <td>[0.34018707275390625, 0.013311447575688362, 0....</td>\n",
       "      <td>[0.017957456409931183, 0.0021609694231301546, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0724908784031868, 0.003055910812690854, 0.0...</td>\n",
       "      <td>[0.0441509485244751, 0.0016689085168763995, 0....</td>\n",
       "      <td>[0.04624519497156143, 0.004924003966152668, 0....</td>\n",
       "      <td>[0.11401460319757462, 0.029382823035120964, 0....</td>\n",
       "      <td>[0.11253754794597626, 0.08178599923849106, 0.0...</td>\n",
       "      <td>[None, None, 0.09205344319343567]</td>\n",
       "      <td>[0.1962161660194397, 0.03035125695168972, 0.02...</td>\n",
       "      <td>[0.21560074388980865, 0.030698880553245544, 0....</td>\n",
       "      <td>[0.2403903752565384, 0.036647979170084, 0.0196...</td>\n",
       "      <td>[0.2060079425573349, 0.013258460909128189, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.025960002094507217, 0.0028873037081211805, ...</td>\n",
       "      <td>[0.19044746458530426, 0.012958797626197338, 0....</td>\n",
       "      <td>[None, None, 0.028950467705726624]</td>\n",
       "      <td>[0.06389091908931732, 0.004681485705077648, 0....</td>\n",
       "      <td>[0.06486066430807114, 0.008367716334760189, 0....</td>\n",
       "      <td>[0.23657678067684174, 0.3340807259082794, 0.23...</td>\n",
       "      <td>[0.13827574253082275, 0.06782031059265137, 0.1...</td>\n",
       "      <td>[0.05339166149497032, 0.005844631232321262, 0....</td>\n",
       "      <td>[0.1670031100511551, 0.005232616793364286, 0.0...</td>\n",
       "      <td>[0.029141930863261223, 0.006851397454738617, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.11921197921037674, 0, 0.01532479259185493]</td>\n",
       "      <td>[0.13816586136817932, 0, 0.01868689541394512]</td>\n",
       "      <td>[0.06885050237178802, 0, 0.016114022272328537]</td>\n",
       "      <td>[0.21876591444015503, 0, 0.026555464913447697]</td>\n",
       "      <td>[0.05607566609978676, 0, 0.008554211778876683]</td>\n",
       "      <td>[None, 0, 0.18107843461136022]</td>\n",
       "      <td>[0.17899048328399658, 0, 0.007928416909029087]</td>\n",
       "      <td>[0.07669304311275482, 0, 0.014362408236290017]</td>\n",
       "      <td>[0.17239488661289215, 0, 0.08554266517361005]</td>\n",
       "      <td>[0.2141619473695755, 0, 0.257558507223924]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.10045278072357178, 0, 0.016710910635689896]</td>\n",
       "      <td>[0.2172575294971466, 0, 0.025304595318933327]</td>\n",
       "      <td>[None, 0, 0.08060755083958308]</td>\n",
       "      <td>[0.29512691497802734, 0, 0.05323744503160318]</td>\n",
       "      <td>[0.11326480656862259, 0, 0.009244329140832027]</td>\n",
       "      <td>[0.037892572581768036, 0, 0.037050863107045494]</td>\n",
       "      <td>[0.032265614718198776, 0, 0.0729232303177317]</td>\n",
       "      <td>[0.05577797442674637, 0, 0.01054172085908552]</td>\n",
       "      <td>[0.35597968101501465, 0, 0.08751298813149333]</td>\n",
       "      <td>[0.05453604459762573, 0, 0.011231241204465428]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.11233010143041611, 0.0022868551313877106, 0...</td>\n",
       "      <td>[0.0696071982383728, 0.00555694755166769, 0.01...</td>\n",
       "      <td>[0.06688571721315384, 0.004095192067325115, 0....</td>\n",
       "      <td>[0.1629549264907837, 0.14536771178245544, 0.02...</td>\n",
       "      <td>[0.08566178381443024, 0.06063935160636902, 0.1...</td>\n",
       "      <td>[None, None, 0.3909915164113045]</td>\n",
       "      <td>[0.15674979984760284, 0.08858616650104523, 0.0...</td>\n",
       "      <td>[0.2349795550107956, 0.0018904487369582057, 0....</td>\n",
       "      <td>[0.25021985173225403, 0.6390978097915649, 0.04...</td>\n",
       "      <td>[0.2568792998790741, 0.014520961791276932, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.038216110318899155, 0.005263861268758774, 0...</td>\n",
       "      <td>[0.12238343805074692, 0.05931299924850464, 0.0...</td>\n",
       "      <td>[None, None, 0.03817640943452716]</td>\n",
       "      <td>[0.09828534722328186, 0.009946794249117374, 0....</td>\n",
       "      <td>[0.051911190152168274, 0.2808518707752228, 0.0...</td>\n",
       "      <td>[0.17751213908195496, 0.08215691894292831, 0.2...</td>\n",
       "      <td>[0.14006930589675903, 0.024958673864603043, 0....</td>\n",
       "      <td>[0.05296207591891289, 0.13199752569198608, 0.0...</td>\n",
       "      <td>[0.15917706489562988, 0.01297526340931654, 0.0...</td>\n",
       "      <td>[0.03596600890159607, 0.0024232380092144012, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.13762447237968445, 0.011282742023468018, 0....</td>\n",
       "      <td>[0.1846502423286438, 0.013612054288387299, 0.0...</td>\n",
       "      <td>[0.09273673593997955, 0.008143377490341663, 0....</td>\n",
       "      <td>[0.2993708550930023, 0.029747437685728073, 0.0...</td>\n",
       "      <td>[0.024045540019869804, 0.04573961719870567, 0....</td>\n",
       "      <td>[None, None, 0.17476380243897438]</td>\n",
       "      <td>[0.07571069151163101, 0.0635836198925972, 0.00...</td>\n",
       "      <td>[0.06732875853776932, 0.021565068513154984, 0....</td>\n",
       "      <td>[0.14015096426010132, 0.04658352956175804, 0.0...</td>\n",
       "      <td>[0.23363099992275238, 0.005424466449767351, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.12284506857395172, 0.011654037982225418, 0....</td>\n",
       "      <td>[0.12852677702903748, 0.1803823858499527, 0.00...</td>\n",
       "      <td>[None, None, 0.060818194411695004]</td>\n",
       "      <td>[0.5955402851104736, 0.01081307977437973, 0.05...</td>\n",
       "      <td>[0.05567222088575363, 0.04099632054567337, 0.0...</td>\n",
       "      <td>[0.0194998811930418, 0.11610786616802216, 0.01...</td>\n",
       "      <td>[0.022709805518388748, 0.035930514335632324, 0...</td>\n",
       "      <td>[0.05819540470838547, 0.05966867133975029, 0.0...</td>\n",
       "      <td>[0.35029497742652893, 0.007299954537302256, 0....</td>\n",
       "      <td>[0.06962665170431137, 0.005042276810854673, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          admiration  \\\n",
       "0  [0.051815811544656754, 0.015896273776888847, 0...   \n",
       "1  [0.0724908784031868, 0.003055910812690854, 0.0...   \n",
       "2      [0.11921197921037674, 0, 0.01532479259185493]   \n",
       "3  [0.11233010143041611, 0.0022868551313877106, 0...   \n",
       "4  [0.13762447237968445, 0.011282742023468018, 0....   \n",
       "\n",
       "                                           adoration  \\\n",
       "0  [0.046310193836688995, 0.005779789295047522, 0...   \n",
       "1  [0.0441509485244751, 0.0016689085168763995, 0....   \n",
       "2      [0.13816586136817932, 0, 0.01868689541394512]   \n",
       "3  [0.0696071982383728, 0.00555694755166769, 0.01...   \n",
       "4  [0.1846502423286438, 0.013612054288387299, 0.0...   \n",
       "\n",
       "                              aesthetic appreciation  \\\n",
       "0  [0.04528449475765228, 0.008344665169715881, 0....   \n",
       "1  [0.04624519497156143, 0.004924003966152668, 0....   \n",
       "2     [0.06885050237178802, 0, 0.016114022272328537]   \n",
       "3  [0.06688571721315384, 0.004095192067325115, 0....   \n",
       "4  [0.09273673593997955, 0.008143377490341663, 0....   \n",
       "\n",
       "                                           amusement  \\\n",
       "0  [0.05977936461567879, 0.06531573086977005, 0.0...   \n",
       "1  [0.11401460319757462, 0.029382823035120964, 0....   \n",
       "2     [0.21876591444015503, 0, 0.026555464913447697]   \n",
       "3  [0.1629549264907837, 0.14536771178245544, 0.02...   \n",
       "4  [0.2993708550930023, 0.029747437685728073, 0.0...   \n",
       "\n",
       "                                               anger  \\\n",
       "0  [0.08618035167455673, 0.014928092248737812, 0....   \n",
       "1  [0.11253754794597626, 0.08178599923849106, 0.0...   \n",
       "2     [0.05607566609978676, 0, 0.008554211778876683]   \n",
       "3  [0.08566178381443024, 0.06063935160636902, 0.1...   \n",
       "4  [0.024045540019869804, 0.04573961719870567, 0....   \n",
       "\n",
       "                           annoyance  \\\n",
       "0   [None, None, 0.0787773035466671]   \n",
       "1  [None, None, 0.09205344319343567]   \n",
       "2     [None, 0, 0.18107843461136022]   \n",
       "3   [None, None, 0.3909915164113045]   \n",
       "4  [None, None, 0.17476380243897438]   \n",
       "\n",
       "                                             anxiety  \\\n",
       "0  [0.2048976570367813, 0.22192993760108948, 0.01...   \n",
       "1  [0.1962161660194397, 0.03035125695168972, 0.02...   \n",
       "2     [0.17899048328399658, 0, 0.007928416909029087]   \n",
       "3  [0.15674979984760284, 0.08858616650104523, 0.0...   \n",
       "4  [0.07571069151163101, 0.0635836198925972, 0.00...   \n",
       "\n",
       "                                                 awe  \\\n",
       "0  [0.05436728522181511, 0.02884811908006668, 0.0...   \n",
       "1  [0.21560074388980865, 0.030698880553245544, 0....   \n",
       "2     [0.07669304311275482, 0, 0.014362408236290017]   \n",
       "3  [0.2349795550107956, 0.0018904487369582057, 0....   \n",
       "4  [0.06732875853776932, 0.021565068513154984, 0....   \n",
       "\n",
       "                                         awkwardness  \\\n",
       "0  [0.15164369344711304, 0.03940080106258392, 0.0...   \n",
       "1  [0.2403903752565384, 0.036647979170084, 0.0196...   \n",
       "2      [0.17239488661289215, 0, 0.08554266517361005]   \n",
       "3  [0.25021985173225403, 0.6390978097915649, 0.04...   \n",
       "4  [0.14015096426010132, 0.04658352956175804, 0.0...   \n",
       "\n",
       "                                             boredom  ...  \\\n",
       "0  [0.3025617003440857, 0.0033794636838138103, 0....  ...   \n",
       "1  [0.2060079425573349, 0.013258460909128189, 0.0...  ...   \n",
       "2         [0.2141619473695755, 0, 0.257558507223924]  ...   \n",
       "3  [0.2568792998790741, 0.014520961791276932, 0.0...  ...   \n",
       "4  [0.23363099992275238, 0.005424466449767351, 0....  ...   \n",
       "\n",
       "                                             romance  \\\n",
       "0  [0.03606966510415077, 0.003395841922610998, 0....   \n",
       "1  [0.025960002094507217, 0.0028873037081211805, ...   \n",
       "2     [0.10045278072357178, 0, 0.016710910635689896]   \n",
       "3  [0.038216110318899155, 0.005263861268758774, 0...   \n",
       "4  [0.12284506857395172, 0.011654037982225418, 0....   \n",
       "\n",
       "                                             sadness  \\\n",
       "0  [0.5214796662330627, 0.023176860064268112, 0.0...   \n",
       "1  [0.19044746458530426, 0.012958797626197338, 0....   \n",
       "2      [0.2172575294971466, 0, 0.025304595318933327]   \n",
       "3  [0.12238343805074692, 0.05931299924850464, 0.0...   \n",
       "4  [0.12852677702903748, 0.1803823858499527, 0.00...   \n",
       "\n",
       "                              sarcasm  \\\n",
       "0  [None, None, 0.045924624986946584]   \n",
       "1  [None, None, 0.028950467705726624]   \n",
       "2      [None, 0, 0.08060755083958308]   \n",
       "3   [None, None, 0.03817640943452716]   \n",
       "4  [None, None, 0.060818194411695004]   \n",
       "\n",
       "                                        satisfaction  \\\n",
       "0  [0.08109661191701889, 0.00422081770375371, 0.0...   \n",
       "1  [0.06389091908931732, 0.004681485705077648, 0....   \n",
       "2      [0.29512691497802734, 0, 0.05323744503160318]   \n",
       "3  [0.09828534722328186, 0.009946794249117374, 0....   \n",
       "4  [0.5955402851104736, 0.01081307977437973, 0.05...   \n",
       "\n",
       "                                               shame  \\\n",
       "0  [0.13604705035686493, 0.03896016255021095, 0.0...   \n",
       "1  [0.06486066430807114, 0.008367716334760189, 0....   \n",
       "2     [0.11326480656862259, 0, 0.009244329140832027]   \n",
       "3  [0.051911190152168274, 0.2808518707752228, 0.0...   \n",
       "4  [0.05567222088575363, 0.04099632054567337, 0.0...   \n",
       "\n",
       "                                 surprise (negative)  \\\n",
       "0  [0.0438678115606308, 0.12426678091287613, 0.65...   \n",
       "1  [0.23657678067684174, 0.3340807259082794, 0.23...   \n",
       "2    [0.037892572581768036, 0, 0.037050863107045494]   \n",
       "3  [0.17751213908195496, 0.08215691894292831, 0.2...   \n",
       "4  [0.0194998811930418, 0.11610786616802216, 0.01...   \n",
       "\n",
       "                                 surprise (positive)  \\\n",
       "0  [0.021023310720920563, 0.05467357486486435, 0....   \n",
       "1  [0.13827574253082275, 0.06782031059265137, 0.1...   \n",
       "2      [0.032265614718198776, 0, 0.0729232303177317]   \n",
       "3  [0.14006930589675903, 0.024958673864603043, 0....   \n",
       "4  [0.022709805518388748, 0.035930514335632324, 0...   \n",
       "\n",
       "                                            sympathy  \\\n",
       "0  [0.07115799933671951, 0.014430238865315914, 0....   \n",
       "1  [0.05339166149497032, 0.005844631232321262, 0....   \n",
       "2      [0.05577797442674637, 0, 0.01054172085908552]   \n",
       "3  [0.05296207591891289, 0.13199752569198608, 0.0...   \n",
       "4  [0.05819540470838547, 0.05966867133975029, 0.0...   \n",
       "\n",
       "                                           tiredness  \\\n",
       "0  [0.34018707275390625, 0.013311447575688362, 0....   \n",
       "1  [0.1670031100511551, 0.005232616793364286, 0.0...   \n",
       "2      [0.35597968101501465, 0, 0.08751298813149333]   \n",
       "3  [0.15917706489562988, 0.01297526340931654, 0.0...   \n",
       "4  [0.35029497742652893, 0.007299954537302256, 0....   \n",
       "\n",
       "                                             triumph  \n",
       "0  [0.017957456409931183, 0.0021609694231301546, ...  \n",
       "1  [0.029141930863261223, 0.006851397454738617, 0...  \n",
       "2     [0.05453604459762573, 0, 0.011231241204465428]  \n",
       "3  [0.03596600890159607, 0.0024232380092144012, 0...  \n",
       "4  [0.06962665170431137, 0.005042276810854673, 0....  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfused_data = get_emotion_scores(df)\n",
    "unfused_data[all_emotions].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fab4de4-d339-4d41-9a49-0ba49e0bee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>adoration</th>\n",
       "      <th>aesthetic appreciation</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awe</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>romance</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise (negative)</th>\n",
       "      <th>surprise (positive)</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.089333</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0.062359</td>\n",
       "      <td>0.171528</td>\n",
       "      <td>0.113535</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.445982</td>\n",
       "      <td>0.163203</td>\n",
       "      <td>0.238960</td>\n",
       "      <td>0.316508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.630715</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>0.091712</td>\n",
       "      <td>0.202038</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.254803</td>\n",
       "      <td>0.198318</td>\n",
       "      <td>0.358406</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>0.213493</td>\n",
       "      <td>0.092053</td>\n",
       "      <td>0.253349</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.296702</td>\n",
       "      <td>0.225344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.205501</td>\n",
       "      <td>0.028950</td>\n",
       "      <td>0.073580</td>\n",
       "      <td>0.075701</td>\n",
       "      <td>0.807173</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134537</td>\n",
       "      <td>0.156853</td>\n",
       "      <td>0.084965</td>\n",
       "      <td>0.245321</td>\n",
       "      <td>0.064630</td>\n",
       "      <td>0.181078</td>\n",
       "      <td>0.186919</td>\n",
       "      <td>0.091055</td>\n",
       "      <td>0.257938</td>\n",
       "      <td>0.471720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117164</td>\n",
       "      <td>0.242562</td>\n",
       "      <td>0.080608</td>\n",
       "      <td>0.348364</td>\n",
       "      <td>0.122509</td>\n",
       "      <td>0.074943</td>\n",
       "      <td>0.105189</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.443493</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130239</td>\n",
       "      <td>0.094360</td>\n",
       "      <td>0.078352</td>\n",
       "      <td>0.329457</td>\n",
       "      <td>0.306634</td>\n",
       "      <td>0.390992</td>\n",
       "      <td>0.264052</td>\n",
       "      <td>0.254076</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.278212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>0.187018</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.120449</td>\n",
       "      <td>0.339278</td>\n",
       "      <td>0.515166</td>\n",
       "      <td>0.247112</td>\n",
       "      <td>0.190067</td>\n",
       "      <td>0.175593</td>\n",
       "      <td>0.047429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156687</td>\n",
       "      <td>0.200794</td>\n",
       "      <td>0.113619</td>\n",
       "      <td>0.344803</td>\n",
       "      <td>0.145212</td>\n",
       "      <td>0.174764</td>\n",
       "      <td>0.143977</td>\n",
       "      <td>0.092978</td>\n",
       "      <td>0.214089</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135891</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.663136</td>\n",
       "      <td>0.108009</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.070003</td>\n",
       "      <td>0.126150</td>\n",
       "      <td>0.400166</td>\n",
       "      <td>0.116220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admiration  adoration  aesthetic appreciation  amusement     anger  \\\n",
       "0    0.089333   0.064811                0.062359   0.171528  0.113535   \n",
       "1    0.079566   0.047286                0.053845   0.155967  0.213493   \n",
       "2    0.134537   0.156853                0.084965   0.245321  0.064630   \n",
       "3    0.130239   0.094360                0.078352   0.329457  0.306634   \n",
       "4    0.156687   0.200794                0.113619   0.344803  0.145212   \n",
       "\n",
       "   annoyance   anxiety       awe  awkwardness   boredom  ...   romance  \\\n",
       "0   0.078777  0.445982  0.163203     0.238960  0.316508  ...  0.042524   \n",
       "1   0.092053  0.253349  0.260014     0.296702  0.225344  ...  0.029184   \n",
       "2   0.181078  0.186919  0.091055     0.257938  0.471720  ...  0.117164   \n",
       "3   0.390992  0.264052  0.254076     0.929878  0.278212  ...  0.050323   \n",
       "4   0.174764  0.143977  0.092978     0.214089  0.326228  ...  0.135891   \n",
       "\n",
       "    sadness   sarcasm  satisfaction     shame  surprise (negative)  \\\n",
       "0  0.630715  0.045925      0.091712  0.202038             0.818245   \n",
       "1  0.205501  0.028950      0.073580  0.075701             0.807173   \n",
       "2  0.242562  0.080608      0.348364  0.122509             0.074943   \n",
       "3  0.187018  0.038176      0.120449  0.339278             0.515166   \n",
       "4  0.318849  0.060818      0.663136  0.108009             0.154099   \n",
       "\n",
       "   surprise (positive)  sympathy  tiredness   triumph  \n",
       "0             0.254803  0.198318   0.358406  0.022734  \n",
       "1             0.332100  0.061174   0.175412  0.040656  \n",
       "2             0.105189  0.066320   0.443493  0.065767  \n",
       "3             0.247112  0.190067   0.175593  0.047429  \n",
       "4             0.070003  0.126150   0.400166  0.116220  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sum_df = get_simple_sum(unfused_data)\n",
    "simple_sum_df[all_emotions].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9edd038-7542-485d-aea8-043799eed4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>adoration</th>\n",
       "      <th>aesthetic appreciation</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awe</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>romance</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise (negative)</th>\n",
       "      <th>surprise (positive)</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.056042</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.032694</td>\n",
       "      <td>0.133353</td>\n",
       "      <td>0.056697</td>\n",
       "      <td>0.072073</td>\n",
       "      <td>0.084032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.178636</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.059214</td>\n",
       "      <td>0.321627</td>\n",
       "      <td>0.097579</td>\n",
       "      <td>0.069953</td>\n",
       "      <td>0.094682</td>\n",
       "      <td>0.006450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021482</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.044376</td>\n",
       "      <td>0.063782</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.071652</td>\n",
       "      <td>0.082492</td>\n",
       "      <td>0.060317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.054527</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>0.268277</td>\n",
       "      <td>0.110258</td>\n",
       "      <td>0.016567</td>\n",
       "      <td>0.046376</td>\n",
       "      <td>0.011730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037308</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.067814</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>0.049757</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>0.080256</td>\n",
       "      <td>0.162488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>0.066903</td>\n",
       "      <td>0.033453</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>0.018819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036389</td>\n",
       "      <td>0.027845</td>\n",
       "      <td>0.021755</td>\n",
       "      <td>0.098375</td>\n",
       "      <td>0.108510</td>\n",
       "      <td>0.162267</td>\n",
       "      <td>0.077285</td>\n",
       "      <td>0.068758</td>\n",
       "      <td>0.289741</td>\n",
       "      <td>0.074239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>0.107564</td>\n",
       "      <td>0.178850</td>\n",
       "      <td>0.078550</td>\n",
       "      <td>0.058818</td>\n",
       "      <td>0.046973</td>\n",
       "      <td>0.013877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042628</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>0.052428</td>\n",
       "      <td>0.072529</td>\n",
       "      <td>0.042287</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>0.098595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>0.096184</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.181689</td>\n",
       "      <td>0.032499</td>\n",
       "      <td>0.050516</td>\n",
       "      <td>0.022302</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>0.110981</td>\n",
       "      <td>0.036960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0.071324</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.048373</td>\n",
       "      <td>0.204077</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.081708</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>0.189620</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>0.087464</td>\n",
       "      <td>0.030979</td>\n",
       "      <td>0.052773</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.088821</td>\n",
       "      <td>0.018995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.056486</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.158809</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.023827</td>\n",
       "      <td>0.075587</td>\n",
       "      <td>0.055261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.046394</td>\n",
       "      <td>0.108124</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.094530</td>\n",
       "      <td>0.058096</td>\n",
       "      <td>0.023865</td>\n",
       "      <td>0.034967</td>\n",
       "      <td>0.024033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0.097045</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.034304</td>\n",
       "      <td>0.241166</td>\n",
       "      <td>0.032639</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>0.028642</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.104791</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107537</td>\n",
       "      <td>0.027927</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.195332</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.045927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.242322</td>\n",
       "      <td>0.118912</td>\n",
       "      <td>0.060184</td>\n",
       "      <td>0.128714</td>\n",
       "      <td>0.017079</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.078987</td>\n",
       "      <td>0.090496</td>\n",
       "      <td>0.086916</td>\n",
       "      <td>0.077445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044578</td>\n",
       "      <td>0.046066</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.101886</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.017684</td>\n",
       "      <td>0.041382</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>0.047189</td>\n",
       "      <td>0.033711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.065996</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>0.037002</td>\n",
       "      <td>0.209079</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.037378</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.088185</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>0.084472</td>\n",
       "      <td>0.023820</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>0.056874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      admiration  adoration  aesthetic appreciation  amusement     anger  \\\n",
       "0       0.027597   0.019183                0.018094   0.056042  0.032387   \n",
       "1       0.021482   0.012613                0.014718   0.044376  0.063782   \n",
       "2       0.037308   0.043624                0.024562   0.067814  0.018108   \n",
       "3       0.036389   0.027845                0.021755   0.098375  0.108510   \n",
       "4       0.042628   0.053416                0.032012   0.093907  0.052428   \n",
       "...          ...        ...                     ...        ...       ...   \n",
       "1066    0.071324   0.041720                0.035037   0.048373  0.204077   \n",
       "1067    0.056486   0.063593                0.026600   0.158809  0.013411   \n",
       "1068    0.097045   0.117304                0.034304   0.241166  0.032639   \n",
       "1069    0.242322   0.118912                0.060184   0.128714  0.017079   \n",
       "1070    0.065996   0.053870                0.037002   0.209079  0.035115   \n",
       "\n",
       "      annoyance   anxiety       awe  awkwardness   boredom  ...   romance  \\\n",
       "0      0.032694  0.133353  0.056697     0.072073  0.084032  ...  0.011738   \n",
       "1      0.038204  0.071929  0.071652     0.082492  0.060317  ...  0.007818   \n",
       "2      0.075150  0.049757  0.025871     0.080256  0.162488  ...  0.033013   \n",
       "3      0.162267  0.077285  0.068758     0.289741  0.074239  ...  0.014474   \n",
       "4      0.072529  0.042287  0.026191     0.062894  0.098595  ...  0.036261   \n",
       "...         ...       ...       ...          ...       ...  ...       ...   \n",
       "1066   0.014995  0.084030  0.019564     0.081708  0.067054  ...  0.046908   \n",
       "1067   0.046980  0.024601  0.023827     0.075587  0.055261  ...  0.028340   \n",
       "1068   0.018955  0.028642  0.038939     0.104791  0.037836  ...  0.107537   \n",
       "1069   0.006813  0.078987  0.090496     0.086916  0.077445  ...  0.044578   \n",
       "1070   0.018227  0.040667  0.076994     0.082279  0.036772  ...  0.030755   \n",
       "\n",
       "       sadness   sarcasm  satisfaction     shame  surprise (negative)  \\\n",
       "0     0.178636  0.019059      0.025080  0.059214             0.321627   \n",
       "1     0.054527  0.012015      0.020188  0.020587             0.268277   \n",
       "2     0.066903  0.033453      0.098711  0.033241             0.025214   \n",
       "3     0.053279  0.015844      0.033822  0.107564             0.178850   \n",
       "4     0.096184  0.025240      0.181689  0.032499             0.050516   \n",
       "...        ...       ...           ...       ...                  ...   \n",
       "1066  0.189620  0.016446      0.077910  0.087464             0.030979   \n",
       "1067  0.026341  0.046394      0.108124  0.016082             0.094530   \n",
       "1068  0.027927  0.024383      0.195332  0.018134             0.026767   \n",
       "1069  0.046066  0.008377      0.101886  0.019683             0.017684   \n",
       "1070  0.037378  0.017214      0.088185  0.017005             0.070562   \n",
       "\n",
       "      surprise (positive)  sympathy  tiredness   triumph  \n",
       "0                0.097579  0.069953   0.094682  0.006450  \n",
       "1                0.110258  0.016567   0.046376  0.011730  \n",
       "2                0.038641  0.018855   0.128733  0.018819  \n",
       "3                0.078550  0.058818   0.046973  0.013877  \n",
       "4                0.022302  0.037962   0.110981  0.036960  \n",
       "...                   ...       ...        ...       ...  \n",
       "1066             0.052773  0.023990   0.088821  0.018995  \n",
       "1067             0.058096  0.023865   0.034967  0.024033  \n",
       "1068             0.082833  0.030718   0.036446  0.045927  \n",
       "1069             0.041382  0.046068   0.047189  0.033711  \n",
       "1070             0.084472  0.023820   0.025532  0.056874  \n",
       "\n",
       "[1071 rows x 53 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_df = get_relative_weights(unfused_data, 'emotion')\n",
    "weighted_df[all_emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01a39839-8115-47f3-a52d-19fb3ff27b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>adoration</th>\n",
       "      <th>aesthetic appreciation</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awe</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>romance</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise (negative)</th>\n",
       "      <th>surprise (positive)</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029577</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>0.056932</td>\n",
       "      <td>0.037235</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>0.145699</td>\n",
       "      <td>0.054978</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.103212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>0.066385</td>\n",
       "      <td>0.281427</td>\n",
       "      <td>0.087105</td>\n",
       "      <td>0.067152</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.007458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025980</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.051053</td>\n",
       "      <td>0.069961</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.084928</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.066910</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.268350</td>\n",
       "      <td>0.111024</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044123</td>\n",
       "      <td>0.051461</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.080424</td>\n",
       "      <td>0.021224</td>\n",
       "      <td>0.063126</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>0.029956</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.159456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.079497</td>\n",
       "      <td>0.028101</td>\n",
       "      <td>0.114566</td>\n",
       "      <td>0.040069</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>0.035918</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.146311</td>\n",
       "      <td>0.021656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042734</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>0.107780</td>\n",
       "      <td>0.103534</td>\n",
       "      <td>0.136304</td>\n",
       "      <td>0.086403</td>\n",
       "      <td>0.083055</td>\n",
       "      <td>0.303936</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>0.173605</td>\n",
       "      <td>0.082320</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>0.057212</td>\n",
       "      <td>0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.065390</td>\n",
       "      <td>0.037264</td>\n",
       "      <td>0.112556</td>\n",
       "      <td>0.049032</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.046995</td>\n",
       "      <td>0.030358</td>\n",
       "      <td>0.070318</td>\n",
       "      <td>0.108160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.104095</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.217055</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.050650</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.038780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0.064175</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.053293</td>\n",
       "      <td>0.208181</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.100542</td>\n",
       "      <td>0.020269</td>\n",
       "      <td>0.088862</td>\n",
       "      <td>0.076320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>0.228988</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.075471</td>\n",
       "      <td>0.100507</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>0.046238</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.110030</td>\n",
       "      <td>0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.069648</td>\n",
       "      <td>0.079387</td>\n",
       "      <td>0.032593</td>\n",
       "      <td>0.195891</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.039463</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.027827</td>\n",
       "      <td>0.087104</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.038971</td>\n",
       "      <td>0.133481</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.082055</td>\n",
       "      <td>0.052406</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>0.028907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0.108637</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>0.039373</td>\n",
       "      <td>0.278991</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.031056</td>\n",
       "      <td>0.043380</td>\n",
       "      <td>0.109429</td>\n",
       "      <td>0.041778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109774</td>\n",
       "      <td>0.029572</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.223909</td>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.040728</td>\n",
       "      <td>0.052281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.233351</td>\n",
       "      <td>0.128718</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.084898</td>\n",
       "      <td>0.092022</td>\n",
       "      <td>0.095969</td>\n",
       "      <td>0.092747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050507</td>\n",
       "      <td>0.054020</td>\n",
       "      <td>0.007037</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.019256</td>\n",
       "      <td>0.042839</td>\n",
       "      <td>0.046920</td>\n",
       "      <td>0.057508</td>\n",
       "      <td>0.037345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.078236</td>\n",
       "      <td>0.064814</td>\n",
       "      <td>0.040973</td>\n",
       "      <td>0.245541</td>\n",
       "      <td>0.041390</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>0.045749</td>\n",
       "      <td>0.092411</td>\n",
       "      <td>0.089059</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.041455</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>0.105533</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>0.072474</td>\n",
       "      <td>0.092360</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>0.030237</td>\n",
       "      <td>0.069922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      admiration  adoration  aesthetic appreciation  amusement     anger  \\\n",
       "0       0.029577   0.021385                0.020496   0.056932  0.037235   \n",
       "1       0.025980   0.015418                0.017582   0.051053  0.069961   \n",
       "2       0.044123   0.051461                0.028015   0.080424  0.021224   \n",
       "3       0.042734   0.031148                0.025663   0.107780  0.103534   \n",
       "4       0.051162   0.065390                0.037264   0.112556  0.049032   \n",
       "...          ...        ...                     ...        ...       ...   \n",
       "1066    0.064175   0.039744                0.032310   0.053293  0.208181   \n",
       "1067    0.069648   0.079387                0.032593   0.195891  0.014508   \n",
       "1068    0.108637   0.134545                0.039373   0.278991  0.034102   \n",
       "1069    0.233351   0.128718                0.064713   0.146993  0.020592   \n",
       "1070    0.078236   0.064814                0.040973   0.245541  0.041390   \n",
       "\n",
       "      annoyance   anxiety       awe  awkwardness   boredom  ...   romance  \\\n",
       "0      0.027463  0.145699  0.054978     0.078883  0.103212  ...  0.013907   \n",
       "1      0.032091  0.083064  0.084928     0.097006  0.073458  ...  0.009504   \n",
       "2      0.063126  0.060991  0.029956     0.085903  0.159456  ...  0.038504   \n",
       "3      0.136304  0.086403  0.083055     0.303936  0.090675  ...  0.016534   \n",
       "4      0.060925  0.046995  0.030358     0.070318  0.108160  ...  0.044248   \n",
       "...         ...       ...       ...          ...       ...  ...       ...   \n",
       "1066   0.012596  0.100542  0.020269     0.088862  0.076320  ...  0.043008   \n",
       "1067   0.039463  0.028765  0.027827     0.087104  0.062400  ...  0.035394   \n",
       "1068   0.015922  0.031056  0.043380     0.109429  0.041778  ...  0.109774   \n",
       "1069   0.005723  0.084898  0.092022     0.095969  0.092747  ...  0.050507   \n",
       "1070   0.015310  0.045749  0.092411     0.089059  0.041985  ...  0.033501   \n",
       "\n",
       "       sadness   sarcasm  satisfaction     shame  surprise (negative)  \\\n",
       "0     0.207200  0.016010      0.029987  0.066385             0.281427   \n",
       "1     0.066910  0.010092      0.024056  0.024690             0.268350   \n",
       "2     0.079497  0.028101      0.114566  0.040069             0.025243   \n",
       "3     0.061008  0.013309      0.039475  0.110739             0.173605   \n",
       "4     0.104095  0.021202      0.217055  0.035432             0.050650   \n",
       "...        ...       ...           ...       ...                  ...   \n",
       "1066  0.228988  0.013815      0.075471  0.100507             0.032229   \n",
       "1067  0.032403  0.038971      0.133481  0.019445             0.082055   \n",
       "1068  0.029572  0.020482      0.223909  0.019679             0.025362   \n",
       "1069  0.054020  0.007037      0.116685  0.022668             0.019256   \n",
       "1070  0.041455  0.014460      0.105533  0.018442             0.072474   \n",
       "\n",
       "      surprise (positive)  sympathy  tiredness   triumph  \n",
       "0                0.087105  0.067152   0.116717  0.007458  \n",
       "1                0.111024  0.019950   0.057141  0.013340  \n",
       "2                0.035918  0.021820   0.146311  0.021656  \n",
       "3                0.082320  0.062051   0.057212  0.015642  \n",
       "4                0.023065  0.041277   0.131175  0.038780  \n",
       "...                   ...       ...        ...       ...  \n",
       "1066             0.046238  0.027791   0.110030  0.018420  \n",
       "1067             0.052406  0.029083   0.041861  0.028907  \n",
       "1068             0.078375  0.032215   0.040728  0.052281  \n",
       "1069             0.042839  0.046920   0.057508  0.037345  \n",
       "1070             0.092360  0.026433   0.030237  0.069922  \n",
       "\n",
       "[1071 rows x 53 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_df = get_relative_weights(unfused_data, 'sentiment')\n",
    "weighted_df[all_emotions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713830a0-869a-4113-afc0-8c74e95b6a5c",
   "metadata": {},
   "source": [
    "## **Predicting the Base Emotion**\n",
    "Now we have an intensity score for each complex emotion. How do we combine the complex emotions to predict the base emotion? We try two approaches.\n",
    "1. **Group Average:** The first approach maps the complex emotions into label groups (each complex emotion is assigned one basic emotion and one sentiment -- either 'positive' or 'negative'). We average the intensities of all the complex emotions that correspond to a given label in order to get the average intensity of that label. In other words, to get the average 'anger' intensity, we average the intensities of the complex emotions that correspond to anger: 'anger', 'annoyance', and 'disapproval'.\n",
    "2. **Classifier:** Our second approach is to train a classifier (a small neural network) that learns the relationship between the complex emotions and each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403aa883-6849-41b5-abe4-ba59cd69652e",
   "metadata": {},
   "source": [
    "#### **Predicting by Group Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d36b06-fe16-49a9-9af6-8c956f107da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_highest_intensity(df, target, show=True):\n",
    "\n",
    "    # get mapping based on prediction target\n",
    "    if target == 'emotion':\n",
    "        mapping = BASIC_TO_COMPLEX\n",
    "    elif target == 'sentiment':\n",
    "        mapping = SENTIMENT_TO_EMOTION\n",
    "    else:\n",
    "        raise Exception('Invalid target')\n",
    "    \n",
    "    labels = sorted(list(mapping.keys()))\n",
    "    intensities = pd.DataFrame()\n",
    "    individual_emotions = pd.DataFrame()\n",
    "\n",
    "    for label in labels:\n",
    "        scores = pd.concat([df[complex_emotion] for complex_emotion in mapping[label]], axis=1)\n",
    "        individual_emotions = pd.concat([individual_emotions, scores], axis=1)\n",
    "\n",
    "        # Suppress runtime warnings for mean of empty slice\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            intensities[label] = np.nanmean(scores, axis=1)\n",
    "        \n",
    "    if show:\n",
    "        print('Intensity of Complex Emotions (Summed Across All Modalities)')\n",
    "        display(individual_emotions.head())\n",
    "        print('Intensity of Each Label (Averaged Across All Complex Emotions Corresponding to that Label)')\n",
    "        display(intensities.head())\n",
    "    return intensities.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e1c4441-d2ab-4502-8ba0-74094fe08dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity of Complex Emotions (Summed Across All Modalities)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>contempt</th>\n",
       "      <th>confusion</th>\n",
       "      <th>craving</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>...</th>\n",
       "      <th>enthusiasm</th>\n",
       "      <th>entrancement</th>\n",
       "      <th>excitement</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>pride</th>\n",
       "      <th>relief</th>\n",
       "      <th>romance</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113535</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.445982</td>\n",
       "      <td>0.238960</td>\n",
       "      <td>0.316508</td>\n",
       "      <td>0.196471</td>\n",
       "      <td>0.496435</td>\n",
       "      <td>0.048553</td>\n",
       "      <td>0.728390</td>\n",
       "      <td>0.118916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016243</td>\n",
       "      <td>0.123442</td>\n",
       "      <td>0.081276</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.057112</td>\n",
       "      <td>0.072393</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.088817</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.213493</td>\n",
       "      <td>0.092053</td>\n",
       "      <td>0.253349</td>\n",
       "      <td>0.296702</td>\n",
       "      <td>0.225344</td>\n",
       "      <td>0.198803</td>\n",
       "      <td>1.931180</td>\n",
       "      <td>0.062355</td>\n",
       "      <td>0.326406</td>\n",
       "      <td>0.019061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.114934</td>\n",
       "      <td>0.122606</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.063270</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.049414</td>\n",
       "      <td>0.053710</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064630</td>\n",
       "      <td>0.181078</td>\n",
       "      <td>0.186919</td>\n",
       "      <td>0.257938</td>\n",
       "      <td>0.471720</td>\n",
       "      <td>0.159819</td>\n",
       "      <td>0.320666</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>0.421771</td>\n",
       "      <td>0.058894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027105</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.250635</td>\n",
       "      <td>0.267914</td>\n",
       "      <td>0.103433</td>\n",
       "      <td>0.302503</td>\n",
       "      <td>0.117164</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306634</td>\n",
       "      <td>0.390992</td>\n",
       "      <td>0.264052</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.278212</td>\n",
       "      <td>0.353361</td>\n",
       "      <td>1.223268</td>\n",
       "      <td>0.078413</td>\n",
       "      <td>0.463078</td>\n",
       "      <td>0.221294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071428</td>\n",
       "      <td>0.148549</td>\n",
       "      <td>0.181257</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.127224</td>\n",
       "      <td>0.090354</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>0.066740</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>0.047429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.145212</td>\n",
       "      <td>0.174764</td>\n",
       "      <td>0.143977</td>\n",
       "      <td>0.214089</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.250662</td>\n",
       "      <td>0.359962</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.249094</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>0.163126</td>\n",
       "      <td>0.180242</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>0.394662</td>\n",
       "      <td>0.134558</td>\n",
       "      <td>0.435780</td>\n",
       "      <td>0.135891</td>\n",
       "      <td>0.116220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger  annoyance   anxiety  awkwardness   boredom  contempt  confusion  \\\n",
       "0  0.113535   0.078777  0.445982     0.238960  0.316508  0.196471   0.496435   \n",
       "1  0.213493   0.092053  0.253349     0.296702  0.225344  0.198803   1.931180   \n",
       "2  0.064630   0.181078  0.186919     0.257938  0.471720  0.159819   0.320666   \n",
       "3  0.306634   0.390992  0.264052     0.929878  0.278212  0.353361   1.223268   \n",
       "4  0.145212   0.174764  0.143977     0.214089  0.326228  0.250662   0.359962   \n",
       "\n",
       "    craving  disappointment  disapproval  ...  enthusiasm  entrancement  \\\n",
       "0  0.048553        0.728390     0.118916  ...    0.016243      0.123442   \n",
       "1  0.062355        0.326406     0.019061  ...    0.020365      0.114934   \n",
       "2  0.045414        0.421771     0.058894  ...    0.027105      0.128915   \n",
       "3  0.078413        0.463078     0.221294  ...    0.071428      0.148549   \n",
       "4  0.061069        0.249094     0.064394  ...    0.013271      0.163126   \n",
       "\n",
       "   excitement  gratitude       joy      love     pride    relief   romance  \\\n",
       "0    0.081276   0.001927  0.057112  0.072393  0.044806  0.088817  0.042524   \n",
       "1    0.122606   0.001607  0.063270  0.047065  0.049414  0.053710  0.029184   \n",
       "2    0.138100   0.012154  0.250635  0.267914  0.103433  0.302503  0.117164   \n",
       "3    0.181257   0.002884  0.127224  0.090354  0.069103  0.066740  0.050323   \n",
       "4    0.180242   0.012297  0.399806  0.394662  0.134558  0.435780  0.135891   \n",
       "\n",
       "    triumph  \n",
       "0  0.022734  \n",
       "1  0.040656  \n",
       "2  0.065767  \n",
       "3  0.047429  \n",
       "4  0.116220  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity of Each Label (Averaged Across All Complex Emotions Corresponding to that Label)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289930</td>\n",
       "      <td>0.071909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266889</td>\n",
       "      <td>0.072645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.144468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.110421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179279</td>\n",
       "      <td>0.205024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative  positive\n",
       "0  0.289930  0.071909\n",
       "1  0.266889  0.072645\n",
       "2  0.171692  0.144468\n",
       "3  0.328500  0.110421\n",
       "4  0.179279  0.205024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_simple = pred_highest_intensity(simple_sum_df, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246c0531-d2d4-4d3f-8a01-1f9180e612c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity of Complex Emotions (Summed Across All Modalities)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>contempt</th>\n",
       "      <th>confusion</th>\n",
       "      <th>craving</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>...</th>\n",
       "      <th>enthusiasm</th>\n",
       "      <th>entrancement</th>\n",
       "      <th>excitement</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>pride</th>\n",
       "      <th>relief</th>\n",
       "      <th>romance</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037235</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>0.145699</td>\n",
       "      <td>0.078883</td>\n",
       "      <td>0.103212</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.162604</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>0.241061</td>\n",
       "      <td>0.041455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.040519</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.018807</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.014630</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.007458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069961</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>0.073458</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.643573</td>\n",
       "      <td>0.020330</td>\n",
       "      <td>0.106612</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.037555</td>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.020659</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>0.017534</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.013340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021224</td>\n",
       "      <td>0.063126</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.159456</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>0.105888</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.139746</td>\n",
       "      <td>0.020531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.042284</td>\n",
       "      <td>0.045489</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.082085</td>\n",
       "      <td>0.087529</td>\n",
       "      <td>0.033940</td>\n",
       "      <td>0.098866</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.021656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103534</td>\n",
       "      <td>0.136304</td>\n",
       "      <td>0.086403</td>\n",
       "      <td>0.303936</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.116955</td>\n",
       "      <td>0.403154</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>0.077145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.048577</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.042106</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>0.022672</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.015642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049032</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.046995</td>\n",
       "      <td>0.070318</td>\n",
       "      <td>0.108160</td>\n",
       "      <td>0.084793</td>\n",
       "      <td>0.120542</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>0.082052</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.053268</td>\n",
       "      <td>0.058746</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.130194</td>\n",
       "      <td>0.128441</td>\n",
       "      <td>0.044165</td>\n",
       "      <td>0.142169</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.038780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger  annoyance   anxiety  awkwardness   boredom  contempt  confusion  \\\n",
       "0  0.037235   0.027463  0.145699     0.078883  0.103212  0.064602   0.162604   \n",
       "1  0.069961   0.032091  0.083064     0.097006  0.073458  0.064992   0.643573   \n",
       "2  0.021224   0.063126  0.060991     0.085903  0.159456  0.053172   0.105888   \n",
       "3  0.103534   0.136304  0.086403     0.303936  0.090675  0.116955   0.403154   \n",
       "4  0.049032   0.060925  0.046995     0.070318  0.108160  0.084793   0.120542   \n",
       "\n",
       "    craving  disappointment  disapproval  ...  enthusiasm  entrancement  \\\n",
       "0  0.015817        0.241061     0.041455  ...    0.005663      0.040519   \n",
       "1  0.020330        0.106612     0.006645  ...    0.007099      0.037555   \n",
       "2  0.014823        0.139746     0.020531  ...    0.009449      0.042284   \n",
       "3  0.025555        0.152225     0.077145  ...    0.024901      0.048577   \n",
       "4  0.020044        0.082052     0.022448  ...    0.004626      0.053268   \n",
       "\n",
       "   excitement  gratitude       joy      love     pride    relief   romance  \\\n",
       "0    0.027140   0.000672  0.018807  0.023674  0.014630  0.029039  0.013907   \n",
       "1    0.040440   0.000560  0.020659  0.015325  0.016141  0.017534  0.009504   \n",
       "2    0.045489   0.004237  0.082085  0.087529  0.033940  0.098866  0.038504   \n",
       "3    0.060417   0.001005  0.042106  0.029773  0.022672  0.021765  0.016534   \n",
       "4    0.058746   0.004287  0.130194  0.128441  0.044165  0.142169  0.044248   \n",
       "\n",
       "    triumph  \n",
       "0  0.007458  \n",
       "1  0.013340  \n",
       "2  0.021656  \n",
       "3  0.015642  \n",
       "4  0.038780  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity of Each Label (Averaged Across All Complex Emotions Corresponding to that Label)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095925</td>\n",
       "      <td>0.023754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087979</td>\n",
       "      <td>0.023774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056861</td>\n",
       "      <td>0.047442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108393</td>\n",
       "      <td>0.036352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059244</td>\n",
       "      <td>0.066984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative  positive\n",
       "0  0.095925  0.023754\n",
       "1  0.087979  0.023774\n",
       "2  0.056861  0.047442\n",
       "3  0.108393  0.036352\n",
       "4  0.059244  0.066984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_weights = pred_highest_intensity(weighted_df, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce93506-8b70-4475-b853-664f7332c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(df, target):\n",
    "    pred = pred_highest_intensity(df, target, show=False)\n",
    "    return np.nanmean(df[target] == pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d3d05-b7ff-4e7e-8470-260d5acf4977",
   "metadata": {},
   "source": [
    "#### **Prediction by Group Average: Simple Sum vs. Weighted Sum Accuracy Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef03912-2ff3-4436-9c39-40fd15849e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at predicting emotion: 32.96\n",
      "Accuracy at predicting sentiment: 44.44\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy at predicting emotion:', round(score(simple_sum_df, 'emotion') * 100, 2))\n",
    "print('Accuracy at predicting sentiment:', round(score(simple_sum_df, 'sentiment') * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b38c770-c647-449f-b87f-e49c37794daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at predicting emotion: 33.43\n",
      "Accuracy at predicting sentiment: 44.54\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy at predicting emotion:', round(score(weighted_df, 'emotion') * 100, 2))\n",
    "print('Accuracy at predicting sentiment:', round(score(weighted_df, 'sentiment') * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01f523-a3c5-4561-bfec-3e18faa7c5c7",
   "metadata": {},
   "source": [
    "**Observations**: Odd that sentiment prediction is identical (a quick look through the data shows that every prediction is the same for all sentences)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3902b-6fdf-4c72-af04-a87da1e18f93",
   "metadata": {},
   "source": [
    "#### **Predicting by Classifier**\n",
    "Let's try training a small neural network that takes in the simple sum complex emotions and predicts the final emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8eda2eb-fa7b-4806-abb6-d20f5074fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbcade85-701a-4c03-8c43-c3be8f20a318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>adoration</th>\n",
       "      <th>aesthetic appreciation</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>awe</th>\n",
       "      <th>awkwardness</th>\n",
       "      <th>boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>romance</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise (negative)</th>\n",
       "      <th>surprise (positive)</th>\n",
       "      <th>sympathy</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>triumph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.089333</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0.062359</td>\n",
       "      <td>0.171528</td>\n",
       "      <td>0.113535</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.445982</td>\n",
       "      <td>0.163203</td>\n",
       "      <td>0.238960</td>\n",
       "      <td>0.316508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>0.630715</td>\n",
       "      <td>0.045925</td>\n",
       "      <td>0.091712</td>\n",
       "      <td>0.202038</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.254803</td>\n",
       "      <td>0.198318</td>\n",
       "      <td>0.358406</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>0.155967</td>\n",
       "      <td>0.213493</td>\n",
       "      <td>0.092053</td>\n",
       "      <td>0.253349</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.296702</td>\n",
       "      <td>0.225344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.205501</td>\n",
       "      <td>0.028950</td>\n",
       "      <td>0.073580</td>\n",
       "      <td>0.075701</td>\n",
       "      <td>0.807173</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134537</td>\n",
       "      <td>0.156853</td>\n",
       "      <td>0.084965</td>\n",
       "      <td>0.245321</td>\n",
       "      <td>0.064630</td>\n",
       "      <td>0.181078</td>\n",
       "      <td>0.186919</td>\n",
       "      <td>0.091055</td>\n",
       "      <td>0.257938</td>\n",
       "      <td>0.471720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117164</td>\n",
       "      <td>0.242562</td>\n",
       "      <td>0.080608</td>\n",
       "      <td>0.348364</td>\n",
       "      <td>0.122509</td>\n",
       "      <td>0.074943</td>\n",
       "      <td>0.105189</td>\n",
       "      <td>0.066320</td>\n",
       "      <td>0.443493</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130239</td>\n",
       "      <td>0.094360</td>\n",
       "      <td>0.078352</td>\n",
       "      <td>0.329457</td>\n",
       "      <td>0.306634</td>\n",
       "      <td>0.390992</td>\n",
       "      <td>0.264052</td>\n",
       "      <td>0.254076</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.278212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>0.187018</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.120449</td>\n",
       "      <td>0.339278</td>\n",
       "      <td>0.515166</td>\n",
       "      <td>0.247112</td>\n",
       "      <td>0.190067</td>\n",
       "      <td>0.175593</td>\n",
       "      <td>0.047429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156687</td>\n",
       "      <td>0.200794</td>\n",
       "      <td>0.113619</td>\n",
       "      <td>0.344803</td>\n",
       "      <td>0.145212</td>\n",
       "      <td>0.174764</td>\n",
       "      <td>0.143977</td>\n",
       "      <td>0.092978</td>\n",
       "      <td>0.214089</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135891</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.663136</td>\n",
       "      <td>0.108009</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.070003</td>\n",
       "      <td>0.126150</td>\n",
       "      <td>0.400166</td>\n",
       "      <td>0.116220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admiration  adoration  aesthetic appreciation  amusement     anger  \\\n",
       "0    0.089333   0.064811                0.062359   0.171528  0.113535   \n",
       "1    0.079566   0.047286                0.053845   0.155967  0.213493   \n",
       "2    0.134537   0.156853                0.084965   0.245321  0.064630   \n",
       "3    0.130239   0.094360                0.078352   0.329457  0.306634   \n",
       "4    0.156687   0.200794                0.113619   0.344803  0.145212   \n",
       "\n",
       "   annoyance   anxiety       awe  awkwardness   boredom  ...   romance  \\\n",
       "0   0.078777  0.445982  0.163203     0.238960  0.316508  ...  0.042524   \n",
       "1   0.092053  0.253349  0.260014     0.296702  0.225344  ...  0.029184   \n",
       "2   0.181078  0.186919  0.091055     0.257938  0.471720  ...  0.117164   \n",
       "3   0.390992  0.264052  0.254076     0.929878  0.278212  ...  0.050323   \n",
       "4   0.174764  0.143977  0.092978     0.214089  0.326228  ...  0.135891   \n",
       "\n",
       "    sadness   sarcasm  satisfaction     shame  surprise (negative)  \\\n",
       "0  0.630715  0.045925      0.091712  0.202038             0.818245   \n",
       "1  0.205501  0.028950      0.073580  0.075701             0.807173   \n",
       "2  0.242562  0.080608      0.348364  0.122509             0.074943   \n",
       "3  0.187018  0.038176      0.120449  0.339278             0.515166   \n",
       "4  0.318849  0.060818      0.663136  0.108009             0.154099   \n",
       "\n",
       "   surprise (positive)  sympathy  tiredness   triumph  \n",
       "0             0.254803  0.198318   0.358406  0.022734  \n",
       "1             0.332100  0.061174   0.175412  0.040656  \n",
       "2             0.105189  0.066320   0.443493  0.065767  \n",
       "3             0.247112  0.190067   0.175593  0.047429  \n",
       "4             0.070003  0.126150   0.400166  0.116220  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = simple_sum_df[all_emotions]\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19f1806-9726-40c1-8519-b948a526d756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprise</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion sentiment\n",
       "0   sadness  negative\n",
       "1  surprise  negative\n",
       "2   neutral   neutral\n",
       "3   sadness  negative\n",
       "4   neutral   neutral"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = simple_sum_df[['emotion', 'sentiment']]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4002e827-4ed8-4680-afae-c49732838084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, target):\n",
    "    '''\n",
    "    @param target is either 'emotion' or 'sentiment'\n",
    "    '''\n",
    "    inputs = df[all_emotions]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, labels[target], test_size=0.2, random_state=42)\n",
    "    model = MLPClassifier(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    display_acc = round(accuracy * 100, 2)\n",
    "    print(f\"Accuracy at predicting {target} is {display_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02fe4346-68d9-4568-9f7a-05c52f0c5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For simple sum:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\J\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at predicting sentiment is 53.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\J\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at predicting emotion is 53.95%\n",
      "For weighted sum:\n",
      "Accuracy at predicting sentiment is 60.0%\n",
      "Accuracy at predicting emotion is 53.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\J\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"For simple sum:\")\n",
    "train_model(simple_sum_df, 'sentiment')\n",
    "train_model(simple_sum_df, 'emotion')\n",
    "\n",
    "print(\"For weighted sum:\")\n",
    "train_model(weighted_df, 'sentiment')\n",
    "train_model(weighted_df, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c760743-d08a-4de5-8201-170000873257",
   "metadata": {},
   "source": [
    "**Observations**: The neural network is much better at predicting emotion but less accurate at predicting sentiment (and even worse than random chance). Changing the random state of the train-test split also significantly changes the accuracy, suggesting that the model is probably overfitting and the small sample size of data is skewing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c75517d-a913-4f56-b439-126c5bdade37",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21264\\1547190092.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdisplay_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy at predicting {target} is {display_acc}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfused_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_emotions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mflattened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# TODO: process nan better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtrain_no_fusion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflattened\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'emotion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\J\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "def train_no_fusion(inputs, target):\n",
    "    '''\n",
    "    @param target is either 'emotion' or 'sentiment'\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(inputs, labels[target], test_size=0.2, random_state=42)\n",
    "    model = MLPClassifier(random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    display_acc = round(accuracy * 100, 2)\n",
    "    print(f\"Accuracy at predicting {target} is {display_acc}%\")\n",
    "inputs = np.array(unfused_data[all_emotions].map(lambda row: np.array(row)).values.tolist())\n",
    "flattened = inputs.reshape(inputs.shape[0], -1)\n",
    "# TODO: process nan better\n",
    "train_no_fusion(flattened, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8efe882-f9fe-46ef-a13e-9e7b87ebcc5e",
   "metadata": {},
   "source": [
    "## **Evaluations**\n",
    "Compare multimodal approaches to single-modality approaches. TODO: generate a heat map that has emotion, sentiment on one hand and lang_only, pros_only, simplexgoup, simplexclassifier, etc. on the other side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b72f3b-36a4-4d59-8948-a26ded63bb8b",
   "metadata": {},
   "source": [
    "## **Selecting Significant Emotions**\n",
    "We graph the intensity across all the emotions, on all modalities. We can then choose a threshold for when an emotion is 'significant,' and only use 'significant' emotions to predict the final sentiment of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48884b6-8c26-45db-bb50-838d53943670",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_intensity = simple_sum_df[all_emotions].mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585c696-4ea0-47d3-9b74-bc5482c85190",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = mean_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc4c87-107b-40b8-b778-09c649db321e",
   "metadata": {},
   "source": [
    "# **Note to self: would be good to modularize how modalities are combined (simple vs. relative sum) and then how the basic emotion is predicted (highest intensity vs. neural net)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b4590-8e07-4d6c-84cc-94b41916d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0frMVtWgEaCE"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
