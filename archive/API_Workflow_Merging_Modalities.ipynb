{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "886ecf79",
      "metadata": {
        "id": "886ecf79"
      },
      "source": [
        "# **Transcription with Conversation-Level Sentiment Annotations**\n",
        "Below, we use the Hume and GPT APIs to generate conversation-level sentiment annotations for a Zoom conversation.\n",
        "\n",
        "> We design a two-part pipeline to visualize Zoom meetings with conversation-level sentiment annotations. We first introduce novel metrics to capture conversation-level sentiments along three axes: comprehension, consensus, and cordiality. To obtain these metrics, we first identify each speaker's individual expressed sentiments during each of their responses. To determine speaker sentiment, we segment Zoom recordings by speaker and feed the video data, audio file (including information on voice prosity), and transcript (text content) of each segment to an off-the-shelf model that outputs a quantitative measure of the extent to which the speaker expresses 48 emotions. Afterward, for each segment, we combine the speaker's top 5 emotions with weights, uniformly sampled facial expressions, and spoken words in an instruction-tuned prompt to a multimodal large language model in order to determine conversation-level metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VsRSpa3IbBfV",
      "metadata": {
        "id": "VsRSpa3IbBfV"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "_y0U55mIXpIb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_y0U55mIXpIb",
        "outputId": "08093b07-8d1d-409b-d1c5-ef5e31477904",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hume in c:\\users\\j\\anaconda3\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: httpx[http2]<0.28.0,>=0.27.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.4 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume) (2.7.1)\n",
            "Requirement already satisfied: pydub<0.26.0,>=0.25.1 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume) (0.25.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.3.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume) (4.7.1)\n",
            "Requirement already satisfied: websockets<13.0,>=12.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume) (12.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (3.5.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (3.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume) (4.1.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx[http2]<0.28.0,>=0.27.0->hume) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->hume) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->hume) (2.18.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume) (4.0.0)\n",
            "Requirement already satisfied: hume[stream] in c:\\users\\j\\anaconda3\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: httpx[http2]<0.28.0,>=0.27.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume[stream]) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.4 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume[stream]) (2.7.1)\n",
            "Requirement already satisfied: pydub<0.26.0,>=0.25.1 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume[stream]) (0.25.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.3.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume[stream]) (4.7.1)\n",
            "Requirement already satisfied: websockets<13.0,>=12.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from hume[stream]) (12.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (3.5.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (3.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (4.1.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->hume[stream]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->hume[stream]) (2.18.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]<0.28.0,>=0.27.0->hume[stream]) (4.0.0)\n",
            "Requirement already satisfied: openai in c:\\users\\j\\anaconda3\\lib\\site-packages (1.24.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\j\\anaconda3\\lib\\site-packages (from openai) (4.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\j\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: certifi in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\j\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\j\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\j\\anaconda3\\lib\\site-packages (0.21.0)\n",
            "Requirement already satisfied: pydub in c:\\users\\j\\anaconda3\\lib\\site-packages (0.25.1)\n",
            "Requirement already satisfied: ffmpeg in c:\\users\\j\\anaconda3\\lib\\site-packages (1.4)\n",
            "Requirement already satisfied: moviepy in c:\\users\\j\\anaconda3\\lib\\site-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (1.24.3)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (2.26.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\j\\anaconda3\\lib\\site-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\j\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\j\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
            "Requirement already satisfied: colorama in c:\\users\\j\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
            "Requirement already satisfied: webvtt-py in c:\\users\\j\\anaconda3\\lib\\site-packages (0.4.6)\n",
            "Requirement already satisfied: docopt in c:\\users\\j\\anaconda3\\lib\\site-packages (from webvtt-py) (0.6.2)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\j\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\j\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "# Install libraries\n",
        "!pip install hume\n",
        "!pip install hume[stream]\n",
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install pydub\n",
        "!pip install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install webvtt-py\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "99e95c11",
      "metadata": {
        "id": "99e95c11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "import base64\n",
        "from pydub import AudioSegment\n",
        "from hume import HumeBatchClient\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab import userdata\n",
        "import webvtt\n",
        "# from google.colab import userdata\n",
        "import cv2\n",
        "from moviepy.editor import VideoFileClip\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737f631d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "20b38794",
      "metadata": {},
      "source": [
        "## Merge three Modalities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e2183c",
      "metadata": {},
      "source": [
        "## 1. Merge language to sentenses, and average scores for each emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3ca923b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-00.000_00-00-06.380_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-06.590_00-00-07.092_Rachel_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-07.092_00-00-09.224_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-09.224_00-00-09.546_Monica_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-10.385_00-00-16.933_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-18.602_00-00-21.145_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-21.939_00-00-26.776_Rachel_surprise_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-27.236_00-00-28.903_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-30.697_00-00-34.617_Rachel_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-35.869_00-00-36.953_Monica_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-40.290_00-00-43.042_Rachel_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-43.252_00-00-45.044_Monica_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-46.171_00-00-48.005_Rachel_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-48.215_00-00-49.715_Monica_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-00.000_00-00-03.544_Joey_fear_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-03.712_00-00-06.797_Phoebe_fear_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-08.550_00-00-10.009_Joey_fear_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-10.176_00-00-15.055_Phoebe_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-16.516_00-00-18.518_Joey_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-18.518_00-00-20.324_Phoebe_surprise_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-20.437_00-00-21.119_Joey_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-21.119_00-00-23.659_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-24.441_00-00-30.154_Joey_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-26.026_00-00-30.154_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-31.322_00-00-33.073_Joey_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-33.241_00-00-35.784_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-37.495_00-00-41.957_Joey_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-42.542_00-00-43.214_Phoebe_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-43.214_00-00-45.274_Phoebe_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-45.795_00-00-48.547_Phoebe_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-48.798_00-00-51.341_Phoebe_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-52.677_00-00-55.430_Phoebe_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-55.430_00-00-55.569_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage Manager_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage-Manager_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-03.003_00-00-05.171_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-05.339_00-00-08.124_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-08.342_00-00-10.259_Lauren_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-10.427_00-00-12.595_Kate_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-12.763_00-00-14.222_Lauren_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-17.351_00-00-19.352_Joey_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-21.480_00-00-23.856_Lauren_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-24.691_00-00-27.652_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-33.867_00-00-40.540_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-41.208_00-00-45.795_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-46.046_00-00-51.217_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-52.886_00-01-09.694_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-11.405_00-01-17.368_Joey_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-17.995_00-01-20.454_Joey_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-23.720_00-01-38.431_Joey_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-46.190_00-01-48.482_Lauren_sadness_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-00.000_00-00-01.835_Ross_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-02.002_00-00-04.838_Rachel_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-05.047_00-00-07.007_Ross_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-08.175_00-00-12.304_Rachel_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-12.554_00-00-13.950_Ross_surprise_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-14.139_00-00-17.934_Rachel_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-18.852_00-00-21.021_Ross_surprise_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-21.188_00-00-25.525_Ross_anger_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-25.692_00-00-27.277_Ross_disgust_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.277_00-00-27.786_Mrs.-Green_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.903_00-00-30.113_Ross_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-00.000_00-00-08.883_Monica_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.095_00-00-11.597_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.597_00-00-13.613_Chandler_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-13.722_00-00-18.726_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-16.726_00-00-18.726_Monica_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-19.854_00-00-21.566_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-21.566_00-00-22.586_Monica_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-22.690_00-00-27.152_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-30.865_00-00-31.948_Monica_surprise_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-32.116_00-00-34.450_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-35.035_00-00-36.911_Monica_surprise_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-38.372_00-00-44.294_Phoebe_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-46.338_00-00-49.924_Chandler_surprise_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-51.510_00-00-55.013_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-56.140_00-00-59.934_Monica_fear_negative_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-01.353_00-01-07.233_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-08.944_00-01-17.285_Ross_surprise_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-18.954_00-01-22.790_Phoebe_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-23.959_00-01-25.851_Rachel_surprise_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-25.851_00-01-26.349_All_neutral_neutral_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-26.462_00-01-28.006_Rachel_joy_positive_lang_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-28.006_00-01-29.516_Ross_neutral_neutral_lang_processed.json\n",
            "All files processed or skipped if already existing.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def process_json_file(filepath, output_directory):\n",
        "    # Determine output file path\n",
        "    output_path = os.path.join(output_directory, os.path.basename(filepath).replace('_lang.json', '_lang_processed.json'))\n",
        "    \n",
        "    # Skip processing if the file already exists\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Skipping existing file: {output_path}\")\n",
        "        return\n",
        "    \n",
        "    # Read JSON file\n",
        "    with open(filepath, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    # Navigate to the predictions in JSON structure\n",
        "    predictions = data[0][\"results\"][\"predictions\"][0][\"models\"][\"language\"][\"grouped_predictions\"][0][\"predictions\"]\n",
        "\n",
        "    # Concatenate text to form full sentence\n",
        "    full_sentence = \" \".join([pred[\"text\"] for pred in predictions])\n",
        "    \n",
        "    # Calculate average emotion scores\n",
        "    emotion_scores = {}\n",
        "    count_emotions = {}\n",
        "    for pred in predictions:\n",
        "        for emotion in pred[\"emotions\"]:\n",
        "            if emotion[\"name\"] in emotion_scores:\n",
        "                emotion_scores[emotion[\"name\"]] += emotion[\"score\"]\n",
        "                count_emotions[emotion[\"name\"]] += 1\n",
        "            else:\n",
        "                emotion_scores[emotion[\"name\"]] = emotion[\"score\"]\n",
        "                count_emotions[emotion[\"name\"]] = 1\n",
        "    \n",
        "    # Averaging the scores\n",
        "    average_emotion_scores = {emotion: score / count_emotions[emotion] for emotion, score in emotion_scores.items()}\n",
        "    \n",
        "    # Save processed data to a new file\n",
        "    with open(output_path, 'w') as outfile:\n",
        "        json.dump({'sentence': full_sentence, 'emotions': average_emotion_scores}, outfile, indent=4)\n",
        "    print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Directories\n",
        "input_directory = \"./dataset/outputs/hume\"\n",
        "output_directory = \"./dataset/outputs/hume_processed\"\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all files with '_lang.json' suffix\n",
        "json_files = [os.path.join(input_directory, f) for f in os.listdir(input_directory) if f.endswith('_lang.json')]\n",
        "\n",
        "# Process each JSON file\n",
        "for file_path in json_files:\n",
        "    process_json_file(file_path, output_directory)\n",
        "\n",
        "print(\"All files processed or skipped if already existing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f938290b",
      "metadata": {},
      "source": [
        "## 2. Merge face expressions to sentenses, and average scores for each emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6bc61a50",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-00.000_00-00-06.380_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-06.590_00-00-07.092_Rachel_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-07.092_00-00-09.224_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-09.224_00-00-09.546_Monica_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-10.385_00-00-16.933_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-18.602_00-00-21.145_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-21.939_00-00-26.776_Rachel_surprise_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-27.236_00-00-28.903_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-30.697_00-00-34.617_Rachel_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-35.869_00-00-36.953_Monica_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-40.290_00-00-43.042_Rachel_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-43.252_00-00-45.044_Monica_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-46.171_00-00-48.005_Rachel_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-48.215_00-00-49.715_Monica_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-00.000_00-00-03.544_Joey_fear_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-03.712_00-00-06.797_Phoebe_fear_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-08.550_00-00-10.009_Joey_fear_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-10.176_00-00-15.055_Phoebe_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-16.516_00-00-18.518_Joey_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-18.518_00-00-20.324_Phoebe_surprise_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-20.437_00-00-21.119_Joey_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-21.119_00-00-23.659_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-24.441_00-00-30.154_Joey_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-26.026_00-00-30.154_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-31.322_00-00-33.073_Joey_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-33.241_00-00-35.784_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-37.495_00-00-41.957_Joey_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-42.542_00-00-43.214_Phoebe_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-43.214_00-00-45.274_Phoebe_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-45.795_00-00-48.547_Phoebe_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-48.798_00-00-51.341_Phoebe_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-52.677_00-00-55.430_Phoebe_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-55.430_00-00-55.569_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage Manager_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage-Manager_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-03.003_00-00-05.171_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-05.339_00-00-08.124_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-08.342_00-00-10.259_Lauren_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-10.427_00-00-12.595_Kate_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-12.763_00-00-14.222_Lauren_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-17.351_00-00-19.352_Joey_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-21.480_00-00-23.856_Lauren_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-24.691_00-00-27.652_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-33.867_00-00-40.540_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-41.208_00-00-45.795_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-46.046_00-00-51.217_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-52.886_00-01-09.694_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-11.405_00-01-17.368_Joey_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-17.995_00-01-20.454_Joey_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-23.720_00-01-38.431_Joey_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-46.190_00-01-48.482_Lauren_sadness_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-00.000_00-00-01.835_Ross_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-02.002_00-00-04.838_Rachel_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-05.047_00-00-07.007_Ross_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-08.175_00-00-12.304_Rachel_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-12.554_00-00-13.950_Ross_surprise_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-14.139_00-00-17.934_Rachel_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-18.852_00-00-21.021_Ross_surprise_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-21.188_00-00-25.525_Ross_anger_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-25.692_00-00-27.277_Ross_disgust_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.277_00-00-27.786_Mrs.-Green_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.903_00-00-30.113_Ross_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-00.000_00-00-08.883_Monica_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.095_00-00-11.597_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.597_00-00-13.613_Chandler_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-13.722_00-00-18.726_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-16.726_00-00-18.726_Monica_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-19.854_00-00-21.566_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-21.566_00-00-22.586_Monica_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-22.690_00-00-27.152_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-30.865_00-00-31.948_Monica_surprise_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-32.116_00-00-34.450_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-35.035_00-00-36.911_Monica_surprise_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-38.372_00-00-44.294_Phoebe_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-46.338_00-00-49.924_Chandler_surprise_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-51.510_00-00-55.013_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-56.140_00-00-59.934_Monica_fear_negative_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-01.353_00-01-07.233_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-08.944_00-01-17.285_Ross_surprise_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-18.954_00-01-22.790_Phoebe_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-23.959_00-01-25.851_Rachel_surprise_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-25.851_00-01-26.349_All_neutral_neutral_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-26.462_00-01-28.006_Rachel_joy_positive_face_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-28.006_00-01-29.516_Ross_neutral_neutral_face_processed.json\n",
            "All face files processed or skipped if already existing.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def process_face_json_file(filepath, output_directory):\n",
        "    # Determine output file path\n",
        "    output_path = os.path.join(output_directory, os.path.basename(filepath).replace('_face.json', '_face_processed.json'))\n",
        "    \n",
        "    # Skip processing if the file already exists\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Skipping existing file: {output_path}\")\n",
        "        return\n",
        "    \n",
        "    # Read JSON file\n",
        "    with open(filepath, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    # Navigate to the face predictions in JSON structure\n",
        "    predictions = data[0][\"results\"][\"predictions\"]\n",
        "\n",
        "    # Calculate average emotion scores\n",
        "    emotion_scores = {}\n",
        "    count_emotions = {}\n",
        "    for pred in predictions:\n",
        "        for model in pred[\"models\"][\"face\"][\"grouped_predictions\"]:\n",
        "            for emotion in model[\"predictions\"][0][\"emotions\"]:\n",
        "                if emotion[\"name\"] in emotion_scores:\n",
        "                    emotion_scores[emotion[\"name\"]] += emotion[\"score\"]\n",
        "                    count_emotions[emotion[\"name\"]] += 1\n",
        "                else:\n",
        "                    emotion_scores[emotion[\"name\"]] = emotion[\"score\"]\n",
        "                    count_emotions[emotion[\"name\"]] = 1\n",
        "    \n",
        "    # Averaging the scores\n",
        "    average_emotion_scores = {emotion: score / count_emotions[emotion] for emotion, score in emotion_scores.items()}\n",
        "    \n",
        "    # Save processed data to a new file\n",
        "    processed_data = {\n",
        "        \"source\": data[0][\"source\"],\n",
        "        \"results\": {\n",
        "            \"predictions\": [{\n",
        "                \"file\": data[0][\"results\"][\"predictions\"][0][\"file\"],\n",
        "                \"file_type\": \"video_no_audio\",\n",
        "                \"models\": {\n",
        "                    \"face\": {\n",
        "                        \"metadata\": None,\n",
        "                        \"grouped_predictions\": [{\n",
        "                            \"id\": \"average\",\n",
        "                            \"predictions\": [{\n",
        "                                \"frame\": \"average\",\n",
        "                                \"time\": \"average\",\n",
        "                                \"prob\": \"average\",\n",
        "                                \"box\": \"average\",\n",
        "                                \"emotions\": [{\"name\": k, \"score\": v} for k, v in average_emotion_scores.items()]\n",
        "                            }]\n",
        "                        }]\n",
        "                    }\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(output_path, 'w') as outfile:\n",
        "        json.dump(processed_data, outfile, indent=4)\n",
        "    print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Directories\n",
        "input_directory = \"./dataset/outputs/hume\"\n",
        "output_directory = \"./dataset/outputs/hume_processed\"\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all files with '_face.json' suffix\n",
        "json_files = [os.path.join(input_directory, f) for f in os.listdir(input_directory) if f.endswith('_face.json')]\n",
        "\n",
        "# Process each JSON file\n",
        "for file_path in json_files:\n",
        "    process_face_json_file(file_path, output_directory)\n",
        "\n",
        "print(\"All face files processed or skipped if already existing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ce53c8",
      "metadata": {},
      "source": [
        "## process prosody"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "133fa29d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-00.000_00-00-06.380_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-06.590_00-00-07.092_Rachel_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-07.092_00-00-09.224_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-09.224_00-00-09.546_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-10.385_00-00-16.933_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-18.602_00-00-21.145_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-21.939_00-00-26.776_Rachel_surprise_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-27.236_00-00-28.903_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-30.697_00-00-34.617_Rachel_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-35.869_00-00-36.953_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-40.290_00-00-43.042_Rachel_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-43.252_00-00-45.044_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-46.171_00-00-48.005_Rachel_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\113_00-00-48.215_00-00-49.715_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-00.000_00-00-03.544_Joey_fear_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-03.712_00-00-06.797_Phoebe_fear_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-08.550_00-00-10.009_Joey_fear_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-10.176_00-00-15.055_Phoebe_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-16.516_00-00-18.518_Joey_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-18.518_00-00-20.324_Phoebe_surprise_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-20.437_00-00-21.119_Joey_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-21.119_00-00-23.659_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-24.441_00-00-30.154_Joey_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-26.026_00-00-30.154_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-31.322_00-00-33.073_Joey_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-33.241_00-00-35.784_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-37.495_00-00-41.957_Joey_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-42.542_00-00-43.214_Phoebe_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-43.214_00-00-45.274_Phoebe_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-45.795_00-00-48.547_Phoebe_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-48.215_00-00-49.715_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-48.798_00-00-51.341_Phoebe_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-52.677_00-00-55.430_Phoebe_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\30_00-00-55.430_00-00-55.569_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage Manager_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-00.000_00-00-02.251_Stage-Manager_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-03.003_00-00-05.171_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-05.339_00-00-08.124_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-08.342_00-00-10.259_Lauren_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-10.427_00-00-12.595_Kate_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-12.763_00-00-14.222_Lauren_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-17.351_00-00-19.352_Joey_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-21.480_00-00-23.856_Lauren_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-24.691_00-00-27.652_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-33.867_00-00-40.540_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-41.208_00-00-45.795_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-46.046_00-00-51.217_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-48.215_00-00-49.715_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-00-52.886_00-01-09.694_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-11.405_00-01-17.368_Joey_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-17.995_00-01-20.454_Joey_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-23.720_00-01-38.431_Joey_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\56_00-01-46.190_00-01-48.482_Lauren_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-00.000_00-00-01.835_Ross_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-02.002_00-00-04.838_Rachel_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-05.047_00-00-07.007_Ross_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-08.175_00-00-12.304_Rachel_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-12.554_00-00-13.950_Ross_surprise_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-14.139_00-00-17.934_Rachel_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-18.852_00-00-21.021_Ross_surprise_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-21.188_00-00-25.525_Ross_anger_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-25.692_00-00-27.277_Ross_disgust_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.277_00-00-27.786_Mrs.-Green_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-27.903_00-00-30.113_Ross_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\7_00-00-48.215_00-00-49.715_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-00.000_00-00-08.883_Monica_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.095_00-00-11.597_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-11.597_00-00-13.613_Chandler_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-13.722_00-00-18.726_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-16.726_00-00-18.726_Monica_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-19.854_00-00-21.566_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-21.566_00-00-22.586_Monica_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-22.690_00-00-27.152_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-30.865_00-00-31.948_Monica_surprise_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-32.116_00-00-34.450_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-35.035_00-00-36.911_Monica_surprise_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-38.372_00-00-44.294_Phoebe_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-46.338_00-00-49.924_Chandler_surprise_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-48.215_00-00-49.715_Monica_sadness_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-51.510_00-00-55.013_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-00-56.140_00-00-59.934_Monica_fear_negative_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-01.353_00-01-07.233_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-08.944_00-01-17.285_Ross_surprise_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-18.954_00-01-22.790_Phoebe_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-23.959_00-01-25.851_Rachel_surprise_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-25.851_00-01-26.349_All_neutral_neutral_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-26.462_00-01-28.006_Rachel_joy_positive_prosody_processed.json\n",
            "Processed and saved: ./dataset/outputs/hume_processed\\97_00-01-28.006_00-01-29.516_Ross_neutral_neutral_prosody_processed.json\n",
            "All prosody files processed or skipped if already existing.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def process_prosody_json_file(filepath, output_directory):\n",
        "    # Preset emotions based on typical data structure\n",
        "    full_emotions_list = [\n",
        "        \"Admiration\", \"Adoration\", \"Aesthetic Appreciation\", \"Amusement\", \"Anger\", \"Annoyance\",\n",
        "        \"Anxiety\", \"Awe\", \"Awkwardness\", \"Boredom\", \"Calmness\", \"Concentration\", \"Confusion\",\n",
        "        \"Contemplation\", \"Contempt\", \"Contentment\", \"Craving\", \"Desire\", \"Determination\",\n",
        "        \"Disappointment\", \"Disapproval\", \"Disgust\", \"Distress\", \"Doubt\", \"Ecstasy\", \"Embarrassment\",\n",
        "        \"Empathic Pain\", \"Enthusiasm\", \"Entrancement\", \"Envy\", \"Excitement\", \"Fear\", \"Gratitude\",\n",
        "        \"Guilt\", \"Horror\", \"Interest\", \"Joy\", \"Love\", \"Nostalgia\", \"Pain\", \"Pride\", \"Realization\",\n",
        "        \"Relief\", \"Romance\", \"Sadness\", \"Sarcasm\", \"Satisfaction\", \"Shame\", \"Surprise (negative)\",\n",
        "        \"Surprise (positive)\", \"Sympathy\", \"Tiredness\", \"Triumph\"\n",
        "    ]\n",
        "\n",
        "    # Determine output file path\n",
        "    output_path = os.path.join(output_directory, os.path.basename(filepath).replace('_prosody.json', '_prosody_processed.json'))\n",
        "    \n",
        "    # Skip processing if the file already exists\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Skipping existing file: {output_path}\")\n",
        "        return\n",
        "    \n",
        "    # Read JSON file\n",
        "    with open(filepath, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    # Initialize a placeholder for predictions\n",
        "    predictions = []\n",
        "\n",
        "    processed_data = {\n",
        "        \"source\": data[0][\"source\"],\n",
        "        \"results\": {\n",
        "            \"predictions\": [],\n",
        "            \"errors\": data[0][\"results\"].get(\"errors\", [])\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Process predictions if they exist\n",
        "    if data[0][\"results\"][\"predictions\"]:\n",
        "        predictions = data[0][\"results\"][\"predictions\"][0][\"models\"][\"prosody\"][\"grouped_predictions\"][0][\"predictions\"]\n",
        "        \n",
        "        # Calculate average emotion scores\n",
        "        emotion_scores = {}\n",
        "        count_emotions = {}\n",
        "        for pred in predictions:\n",
        "            for emotion in pred[\"emotions\"]:\n",
        "                if emotion[\"name\"] in emotion_scores:\n",
        "                    emotion_scores[emotion[\"name\"]] += emotion[\"score\"]\n",
        "                    count_emotions[emotion[\"name\"]] += 1\n",
        "                else:\n",
        "                    emotion_scores[emotion[\"name\"]] = emotion[\"score\"]\n",
        "                    count_emotions[emotion[\"name\"]] = 1\n",
        "\n",
        "        # Averaging the scores\n",
        "        average_emotion_scores = {emotion: score / count_emotions[emotion] for emotion, score in emotion_scores.items()}\n",
        "    else:\n",
        "        # Handle case with errors by setting all emotion scores to zero\n",
        "        average_emotion_scores = {emotion: 0 for emotion in full_emotions_list}\n",
        "\n",
        "    # Text content logic based on the existence of predictions\n",
        "    text_content = \" \".join([p[\"text\"] for p in predictions]) if predictions else \"Error: No transcribable content.\"\n",
        "\n",
        "    # Create processed predictions with averaged data or zeros in case of errors\n",
        "    processed_data[\"results\"][\"predictions\"].append({\n",
        "        \"file\": data[0][\"source\"][\"filename\"],\n",
        "        \"file_type\": \"audio\",\n",
        "        \"models\": {\n",
        "            \"prosody\": {\n",
        "                \"metadata\": None,\n",
        "                \"grouped_predictions\": [{\n",
        "                    \"id\": \"average\",\n",
        "                    \"predictions\": [{\n",
        "                        \"text\": text_content,\n",
        "                        \"time\": {\"begin\": 0, \"end\": 0},\n",
        "                        \"confidence\": 0,\n",
        "                        \"emotions\": [{\"name\": k, \"score\": v} for k, v in average_emotion_scores.items()]\n",
        "                    }]\n",
        "                }]\n",
        "            }\n",
        "        }\n",
        "    })\n",
        "\n",
        "    # Save processed data to a new file\n",
        "    with open(output_path, 'w') as outfile:\n",
        "        json.dump(processed_data, outfile, indent=4)\n",
        "    print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "# Directories\n",
        "input_directory = \"./dataset/outputs/hume\"\n",
        "output_directory = \"./dataset/outputs/hume_processed\"\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# List all files with '_prosody.json' suffix\n",
        "json_files = [os.path.join(input_directory, f) for f in os.listdir(input_directory) if f.endswith('_prosody.json')]\n",
        "\n",
        "# Process each JSON file\n",
        "for file_path in json_files:\n",
        "    process_prosody_json_file(file_path, output_directory)\n",
        "\n",
        "print(\"All prosody files processed or skipped if already existing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1431f60",
      "metadata": {},
      "source": [
        "# histogram of word count and length"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0frMVtWgEaCE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
